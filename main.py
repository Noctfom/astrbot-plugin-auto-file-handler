from astrbot.api.event import MessageChain
# TODO: v1.6.2 improvements based on AI review\n# -*- coding: utf-8 -*-
"""
AstrBotè‡ªåŠ¨æ–‡ä»¶å¤„ç†å™¨æ’ä»¶ - 1.6.2ç‰ˆæœ¬
å½»åº•ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯å’Œæ·»åŠ è°ƒè¯•å¼€å…³
"""

from astrbot.api.star import Star, register
from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api import logger, AstrBotConfig
import os
import time
import asyncio
import aiohttp
import json
from urllib.parse import urlparse
import re
import zipfile
import tarfile
from collections import defaultdict

# LLMå·¥å…·æ”¯æŒ
try:
    from pydantic import Field
    from pydantic.dataclasses import dataclass
    from astrbot.core.agent.run_context import ContextWrapper
    from astrbot.core.agent.tool import FunctionTool, ToolExecResult
    from astrbot.core.astr_agent_context import AstrAgentContext
    LLM_TOOL_SUPPORT = True
except ImportError:
    LLM_TOOL_SUPPORT = False
    logger.info("[FileHandler-1.6.2] LLMå·¥å…·æ”¯æŒä¸å¯ç”¨")

# å…¨å±€å­˜å‚¨æ’ä»¶å®ä¾‹,ä¾›LLMå·¥å…·è®¿é—®
_plugin_instance = None

# LLMå·¥å…·å®šä¹‰ - å½»åº•ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯
if LLM_TOOL_SUPPORT:
    @dataclass
    class FileListTool(FunctionTool[AstrAgentContext]):
        name: str = "list_user_files"
        description: str = "å½“ç”¨æˆ·è¡¨è¾¾æƒ³è¦æŸ¥çœ‹è‡ªå·±å‘é€ç»™æœºå™¨äººæ–‡ä»¶çš„æ„å›¾æ—¶,åŒ…æ‹¬ä½†ä¸é™äºä»¥ä¸‹è¡¨è¿°:'æŸ¥çœ‹æ–‡ä»¶'ã€'æˆ‘çš„æ–‡ä»¶'ã€'æ–‡ä»¶åˆ—è¡¨'ã€'èƒ½çœ‹åˆ°æˆ‘å‘é€çš„æ–‡ä»¶å—'ã€'æ£€æŸ¥æ–‡ä»¶'ã€'ä¸Šä¼ çš„æ–‡ä»¶'ã€'æ–‡ä»¶è¯¦æƒ…',ç«‹å³ä¸»åŠ¨è°ƒç”¨æ­¤å·¥å…·,ä¸ºç”¨æˆ·æä¾›å®Œæ•´çš„æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨,åŒ…å«æ–‡ä»¶åã€å­˜å‚¨è·¯å¾„ã€æ–‡ä»¶å¤§å°ã€ç±»å‹å’Œä¸Šä¼ æ—¶é—´ç­‰å…³é”®ä¿¡æ¯ã€‚"
        parameters: dict = Field(
            default_factory=lambda: {
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                        "description": "ç”¨æˆ·çš„å”¯ä¸€æ ‡è¯†ç¬¦",
                    },
                },
                "required": ["user_id"],
            }
        )

        async def call(
            self, context: ContextWrapper[AstrAgentContext], **kwargs
        ) -> ToolExecResult:
            user_id = kwargs.get("user_id", "")
            if not user_id:
                # ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯ - ä½¿ç”¨æ­£ç¡®çš„æ–¹å¼åˆ›å»ºå®ä¾‹
                return "é”™è¯¯:ç¼ºå°‘ç”¨æˆ·IDå‚æ•°"
            
            # è·å–æ’ä»¶å®ä¾‹ä»¥è®¿é—®é…ç½®çš„å­˜å‚¨è·¯å¾„
            global _plugin_instance
            if _plugin_instance is None:
                return "é”™è¯¯:æ’ä»¶å®ä¾‹æœªåˆå§‹åŒ–"
            
            # ç¡®ä¿ä½¿ç”¨æœ€æ–°çš„é…ç½®æ•°æ®
            try:
                # ç›´æ¥ä»æ’ä»¶å®ä¾‹è·å–æœ€æ–°é…ç½®
                storage_path = _plugin_instance.storage_path
                debug_mode = _plugin_instance.debug_mode
                if debug_mode:
                    logger.info(f"[FileListTool] ä½¿ç”¨å­˜å‚¨è·¯å¾„: {storage_path}")
            except Exception as e:
                logger.error(f"[FileListTool] è·å–å­˜å‚¨è·¯å¾„æ—¶å‡ºé”™: {e}")
                # ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯
                return f"è·å–å­˜å‚¨è·¯å¾„æ—¶å‡ºé”™: {str(e)}"
            
            user_storage_path = os.path.join(storage_path, f"user_{user_id}")
            
            if not os.path.exists(user_storage_path):
                return "è¯¥ç”¨æˆ·æš‚æ— æ–‡ä»¶"
            
            record_file = os.path.join(user_storage_path, '.file_records.json')
            if not os.path.exists(record_file):
                return "è¯¥ç”¨æˆ·æš‚æ— æ–‡ä»¶è®°å½•"
            
            try:
                with open(record_file, 'r', encoding='utf-8') as f:
                    records = json.load(f)
                    success_records = [r for r in records if r.get('download_status') == 'success']
                
                if not success_records:
                    return "è¯¥ç”¨æˆ·æš‚æ— æ–‡ä»¶"
                
                # æ ¼å¼åŒ–æ–‡ä»¶ä¿¡æ¯
                file_info_list = []
                for record in success_records:
                    filename = record.get('final_filename', 'unknown')
                    filepath = record.get('file_path', 'unknown')
                    filesize = record.get('file_size', 0)
                    filetype = record.get('file_type', 'unknown')
                    receive_time = record.get('receive_time', 0)
                    
                    # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                    if filesize < 1024:
                        size_str = f"{filesize} B"
                    elif filesize < 1024 * 1024:
                        size_str = f"{filesize / 1024:.1f} KB"
                    elif filesize < 1024 * 1024 * 1024:
                        size_str = f"{filesize / (1024 * 1024):.1f} MB"
                    else:
                        size_str = f"{filesize / (1024 * 1024 * 1024):.1f} GB"
                    
                    # æ ¼å¼åŒ–æ—¶é—´
                    time_str = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(receive_time))
                    
                    file_info_list.append({
                        "filename": filename,
                        "filepath": filepath,
                        "size": size_str,
                        "type": filetype,
                        "receive_time": time_str
                    })
                
                # è¿”å›æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²è€Œä¸æ˜¯JSON
                result_str = "ç”¨æˆ·æ–‡ä»¶åˆ—è¡¨:\n"
                for i, file_info in enumerate(file_info_list, 1):
                    result_str += f"{i}. æ–‡ä»¶å: {file_info['filename']}\n"
                    result_str += f"   è·¯å¾„: {file_info['filepath']}\n"
                    result_str += f"   å¤§å°: {file_info['size']}\n"
                    result_str += f"   ç±»å‹: {file_info['type']}\n"
                    result_str += f"   æ—¶é—´: {file_info['receive_time']}\n\n"
                
                # ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯
                return result_str.strip()
                
            except Exception as e:
                logger.error(f"[FileListTool] è¯»å–æ–‡ä»¶ä¿¡æ¯æ—¶å‡ºé”™: {e}")
                # ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯
                return f"è¯»å–æ–‡ä»¶ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}"

@register("auto_file_handler", "Noctfom", "è‡ªåŠ¨æ–‡ä»¶å¤„ç†å™¨", "1.6.2", "")
class PluginMain(Star):
    def _find_target_record(self, records, file_identifier):
        """é€šç”¨æ–‡ä»¶è®°å½•æŸ¥æ‰¾æ–¹æ³•"""
        try:
            # å°è¯•æŒ‰åºå·æŸ¥æ‰¾
            if file_identifier.isdigit():
                index = int(file_identifier) - 1
                if 0 <= index < len(records):
                    return records[index], index

            # æŒ‰æ–‡ä»¶åæ¨¡ç³ŠæŸ¥æ‰¾
            for i, record in enumerate(records):
                if file_identifier in record.get('final_filename', ''):
                    return record, i

            # æŒ‰æ–‡ä»¶åç²¾ç¡®æŸ¥æ‰¾
            for i, record in enumerate(records):
                final_name = record.get('final_filename', '').lower()
                if final_name == file_identifier.lower():
                    return record, i

            return None, -1

        except Exception as e:
            logger.error(f"[1.6.2] æŸ¥æ‰¾æ–‡ä»¶è®°å½•æ—¶å‡ºé”™: {e}")
            return None, -1

    def __init__(self, context, config: AstrBotConfig = None):
        super().__init__(context)
        self.context = context
        self.config = config
        
        # å­˜å‚¨æ’ä»¶å®ä¾‹ä¾›LLMå·¥å…·ä½¿ç”¨
        global _plugin_instance
        _plugin_instance = self
        
        # å­˜å‚¨ç­‰å¾…æ¥æ”¶ç¾¤æ–‡ä»¶çš„è¯·æ±‚ {group_id: {user_id: expire_time}}
        self.pending_group_receives = defaultdict(dict)
        
        if config:
            self.storage_path = config.get('storage_path', '/app/storage/auto_file_handler')
            self.auto_cleanup_enabled = config.get('auto_cleanup_enabled', True)
            self.cleanup_days = config.get('cleanup_days', 7)
            self.send_completion_message = config.get('send_completion_message', True)
            self.max_files_per_user = config.get('max_files_per_user', 5)
            self.max_file_size_mb = config.get('max_file_size_mb', 100)
            self.group_whitelist = config.get('group_whitelist', '')
            self.auto_receive_group_files = config.get('auto_receive_group_files', True)
            self.max_files_per_group = config.get('max_files_per_group', 10)
            self.group_file_receive_timeout = config.get('group_file_receive_timeout', 60)
            self.debug_mode = config.get('debug_mode', False)  # æ–°å¢è°ƒè¯•æ¨¡å¼
            self.auto_read_content = config.get('auto_read_content', False)
            self.max_auto_read_size = config.get('max_auto_read_size', 2000)  # é»˜è®¤100KB
        else:
            self.storage_path = '/app/storage/auto_file_handler'
            self.auto_cleanup_enabled = True
            self.cleanup_days = 7
            self.send_completion_message = True
            self.max_files_per_user = 5
            self.max_file_size_mb = 100
            self.group_whitelist = ''
            self.auto_receive_group_files = True
            self.max_files_per_group = 10
            self.group_file_receive_timeout = 60
            self.debug_mode = False  # é»˜è®¤å…³é—­è°ƒè¯•æ¨¡å¼
            self.auto_read_content = True
            self.max_auto_read_size = 2000  # é»˜è®¤100KB
        
        os.makedirs(self.storage_path, exist_ok=True)
        
        if self.auto_cleanup_enabled:
            asyncio.create_task(self._cleanup_task())
        
        # å¯åŠ¨è¶…æ—¶æ£€æŸ¥ä»»åŠ¡
        asyncio.create_task(self._check_pending_timeouts())
        
        # æ³¨å†ŒLLMå·¥å…·
        if LLM_TOOL_SUPPORT:
            try:
                self.context.add_llm_tools(FileListTool())
                if self.debug_mode:
                    logger.info("[FileHandler-1.6.2] LLMå·¥å…·å·²æ³¨å†Œ")
                    logger.info(f"[FileHandler-1.6.2] å½“å‰å­˜å‚¨è·¯å¾„é…ç½®: {self.storage_path}")
            except Exception as e:
                logger.error(f"[FileHandler-1.6.2] æ³¨å†ŒLLMå·¥å…·æ—¶å‡ºé”™: {e}")
        
        logger.info(f"[FileHandler-1.6.2] æ’ä»¶åˆå§‹åŒ–æˆåŠŸ!")
        if self.debug_mode:
            logger.info(f"[FileHandler-1.6.2] å­˜å‚¨è·¯å¾„: {self.storage_path}")
            logger.info(f"[FileHandler-1.6.2] è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if self.debug_mode else 'å…³é—­'}")
    
    async def _check_pending_timeouts(self):
        """å®šæœŸæ£€æŸ¥ç­‰å¾…æ¥æ”¶çš„è¯·æ±‚æ˜¯å¦è¶…æ—¶"""
        while True:
            try:
                current_time = time.time()
                expired_groups = []
                
                for group_id, pending_users in self.pending_group_receives.items():
                    expired_users = []
                    for user_id, expire_time in pending_users.items():
                        if current_time > expire_time:
                            expired_users.append(user_id)
                    
                    # æ¸…ç†è¿‡æœŸç”¨æˆ·å¹¶å‘é€è¶…æ—¶æé†’
                    for user_id in expired_users:
                        del pending_users[user_id]
                        # å‘é€è¶…æ—¶æé†’
                        if self.debug_mode:
                            logger.info(f"[1.6.2] ç¾¤ {group_id} ç”¨æˆ· {user_id} çš„æ–‡ä»¶æ¥æ”¶è¯·æ±‚å·²è¶…æ—¶")
                    
                    # å¦‚æœè¯¥ç¾¤æ²¡æœ‰ç­‰å¾…çš„ç”¨æˆ·äº†,æ ‡è®°ä¸ºå¯æ¸…ç†
                    if not pending_users:
                        expired_groups.append(group_id)
                
                # æ¸…ç†ç©ºçš„ç¾¤è®°å½•
                for group_id in expired_groups:
                    del self.pending_group_receives[group_id]
                
                await asyncio.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"[1.6.2] æ£€æŸ¥è¶…æ—¶ä»»åŠ¡å‡ºé”™: {e}")
                await asyncio.sleep(10)
                
    async def _handle_file_as_user_message(self, event, file_content: str, filename: str):
        """å°†æ–‡ä»¶å†…å®¹ä½œä¸ºç”¨æˆ·æ¶ˆæ¯å¤„ç†ï¼Œè§¦å‘AstrBotæ­£å¸¸å¯¹è¯æµç¨‹"""
        try:
            # ğŸ”’ é˜²é€’å½’å®‰å…¨æ£€æŸ¥
            if getattr(event, '_auto_file_processed', False):
                logger.info("[AutoRead-AI] ğŸ”’ è·³è¿‡å·²å¤„ç†çš„æ¶ˆæ¯ï¼ˆé˜²é€’å½’ï¼‰")
                return
                
            logger.info(f"[AutoRead-AI] å¼€å§‹å¤„ç†æ–‡ä»¶: {filename}")
            
            # æ­£ç¡®çš„å¯¼å…¥ï¼ˆåªå¯¼å…¥æˆ‘ä»¬ç¡®å®šå­˜åœ¨çš„æ¨¡å—ï¼‰
            from astrbot.core.platform.astrbot_message import AstrBotMessage, MessageMember
            from astrbot.core.message.components import Plain
            from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import AiocqhttpMessageEvent
            import time
            
            # 1. åˆ›å»ºå…¨æ–°çš„å¹²å‡€æ¶ˆæ¯å¯¹è±¡
            simulated_message = AstrBotMessage()
            
            # 2. æ­£ç¡®è®¾ç½®ç”¨æˆ·å’Œä¼šè¯ä¿¡æ¯ï¼ˆåŠ¨æ€è·å–ï¼‰
            simulated_message.message_str = file_content.strip()
            
            # 3. å…³é”®ï¼šæ­£ç¡®è®¾ç½®å‘é€è€…ä¿¡æ¯ï¼ˆä»åŸå§‹eventè·å–ï¼‰
            original_sender = getattr(event.message_obj, 'sender', None)
            if original_sender and hasattr(original_sender, 'user_id'):
                # å¤åˆ¶åŸå§‹å‘é€è€…çš„æ‰€æœ‰å…³é”®ä¿¡æ¯
                simulated_message.sender = MessageMember(user_id=original_sender.user_id)
                simulated_message.sender.nickname = original_sender.nickname if original_sender.nickname else "ç”¨æˆ·"
                simulated_message.user_id = original_sender.user_id
            else:
                # ä»eventè·å–ç”¨æˆ·ä¿¡æ¯
                user_id = getattr(event.message_obj, 'user_id', getattr(event, 'user_id', 'unknown'))
                sender_nickname = getattr(event.message_obj, 'sender_nickname', getattr(event, 'sender_nickname', 'ç”¨æˆ·'))
                
                simulated_message.sender = MessageMember(user_id=user_id)
                simulated_message.sender.nickname = sender_nickname
                simulated_message.user_id = user_id
                
            # ç¡®ä¿æ‰€æœ‰IDä¸€è‡´
            simulated_message.sender_id = simulated_message.user_id
            simulated_message.group_id = getattr(event.message_obj, 'group_id', getattr(event, 'group_id', ''))
            simulated_message.session_id = getattr(event, 'session_id', f"private_{simulated_message.user_id}")
            simulated_message.timestamp = int(time.time())
            simulated_message.unified_msg_origin = getattr(event, 'unified_msg_origin', '')
            simulated_message.type = getattr(event.message_obj, 'type', None)
            
            # 4. åˆ›å»ºçº¯å‡€çš„æ¶ˆæ¯é“¾
            simulated_message.message = [Plain(text=file_content.strip())]
            
            # 5. å…³é”®ï¼šåˆ›å»ºå¹³å°ç‰¹å®šäº‹ä»¶ï¼ˆåŒ…å«botå®¢æˆ·ç«¯ï¼‰
            bot_client = getattr(event, 'bot', None)
            simulated_event = AiocqhttpMessageEvent(
                message_str=simulated_message.message_str,
                message_obj=simulated_message,
                platform_meta=getattr(event, 'platform_meta', None),
                session_id=simulated_message.session_id,
                bot=bot_client,  # å…³é”®ï¼šä¼ é€’botå®¢æˆ·ç«¯ï¼Œè¿™æ ·æ‰èƒ½çœŸæ­£å‘é€æ¶ˆæ¯
            )
            
            # 6. æ·»åŠ é˜²é€’å½’æ ‡è®°
            simulated_event._auto_file_processed = True
            
            # ğŸ” è°ƒè¯•ä¿¡æ¯
            logger.info(f"[AutoRead-AI] åˆ›å»ºæ¨¡æ‹Ÿäº‹ä»¶å®Œæˆ")
            logger.info(f"[AutoRead-AI] ç”¨æˆ·ID: {simulated_message.user_id}")
            logger.info(f"[AutoRead-AI] å‘é€è€…æ˜µç§°: {simulated_message.sender.nickname}")
            logger.info(f"[AutoRead-AI] ä¼šè¯ID: {simulated_message.session_id}")
            logger.info(f"[AutoRead-AI] Botå®¢æˆ·ç«¯: {'å­˜åœ¨' if bot_client else 'ä¸å­˜åœ¨'}")
            
            # 7. æäº¤åˆ°äº‹ä»¶é˜Ÿåˆ—è§¦å‘å®Œæ•´å¤„ç†æµç¨‹
            if hasattr(self.context, '_event_queue') and self.context._event_queue:
                self.context._event_queue.put_nowait(simulated_event)
                logger.info(f"[AutoRead-AI] äº‹ä»¶å·²æäº¤åˆ°é˜Ÿåˆ—")
            else:
                # fallback: ç›´æ¥è°ƒç”¨tool_loop_agentï¼ˆä½†æˆ‘ä»¬å·²ç»çŸ¥é“è¿™ä¸æ˜¯æœ€ä½³æ–¹æ¡ˆï¼‰
                logger.warning("[AutoRead-AI] æ— æ³•ç›´æ¥æäº¤äº‹ä»¶ï¼Œä½¿ç”¨fallbackæ–¹æ¡ˆ")
                chat_provider_id = await self.context.get_current_chat_provider_id(event.unified_msg_origin)
                response = await self.context.tool_loop_agent(
                    prompt=file_content,
                    event=event,
                    chat_provider_id=chat_provider_id
                )
                
                if response and hasattr(response, 'response_text'):
                    await self._send_reply(event, response.response_text)
                else:
                    await self._send_reply(event, "æ–‡æœ¬å¤„ç†æœªå®Œæˆ")
                
        except Exception as e:
            logger.error(f"[AutoRead-AI] å¤„ç†å‡ºé”™: {e}", exc_info=True)
            await self._send_reply(event, "æ–‡æœ¬å¤„ç†å‡ºç°é—®é¢˜")

    async def _send_reply(self, event, message: str):
        """ç»Ÿä¸€çš„æ¶ˆæ¯å‘é€æ–¹æ³•ï¼Œå…¼å®¹ä¸åŒå¹³å°"""
        try:
            # ä½¿ç”¨context.send_messageæ–¹æ³•ï¼ˆæœ€å¯é çš„å‘é€æ–¹å¼ï¼‰
            from astrbot.api.event import MessageChain
            message_chain = MessageChain().message(message)
            await self.context.send_message(event.unified_msg_origin, message_chain)
            logger.info(f"[AutoRead-AI] æ¶ˆæ¯å‘é€æˆåŠŸï¼Œé•¿åº¦: {len(message)}")
        except Exception as e:
            logger.error(f"[AutoRead-AI] æ¶ˆæ¯å‘é€å¤±è´¥: {e}")

    @filter.event_message_type(filter.EventMessageType.ALL)
    async def on_message(self, event: AstrMessageEvent):
        try:
            if not hasattr(event, 'message_obj') or not event.message_obj:
                return
            
            message_obj = event.message_obj
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¾¤èŠæ¶ˆæ¯
            is_group_message = False
            group_id = ""
            if hasattr(message_obj, 'group_id') and message_obj.group_id:
                is_group_message = True
                group_id = str(message_obj.group_id)
            
            # ç¾¤èŠç™½åå•æ£€æŸ¥
            if is_group_message and self.group_whitelist:
                whitelist_groups = [gid.strip() for gid in self.group_whitelist.split(',')]
                if group_id not in whitelist_groups:
                    return  # ä¸åœ¨ç™½åå•ä¸­,ä¸å¤„ç†
            
            # å¤„ç†æ–‡ä»¶æ¶ˆæ¯
            if hasattr(message_obj, 'message') and message_obj.message:
                for i, component in enumerate(message_obj.message):
                    component_name = component.__class__.__name__ if hasattr(component, '__class__') else 'Unknown'
                    
                    if 'file' in component_name.lower() or component_name in ['File', 'FileComponent']:
                        if self.debug_mode:
                            logger.info(f"[1.6.2] æ£€æµ‹åˆ°æ–‡ä»¶ç»„ä»¶ - ç´¢å¼•: {i}, ç±»å‹: {component_name}")
                        
                        # ç¾¤èŠæ–‡ä»¶å¤„ç†
                        if is_group_message:
                            # æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…æ¥æ”¶çš„è¯·æ±‚
                            user_id = self._get_user_id(event)
                            if (group_id in self.pending_group_receives and 
                                user_id in self.pending_group_receives[group_id]):
                                # æœ‰ç­‰å¾…çš„æ¥æ”¶è¯·æ±‚,å¤„ç†æ–‡ä»¶
                                del self.pending_group_receives[group_id][user_id]  # æ¸…ç†ç­‰å¾…çŠ¶æ€
                                await self._handle_group_file_v159(event, component, group_id)
                            elif self.auto_receive_group_files:
                                # è‡ªåŠ¨æ¥æ”¶æ¨¡å¼
                                await self._handle_group_file_v159(event, component, group_id)
                            # å¦åˆ™å¿½ç•¥æ–‡ä»¶(æ²¡æœ‰ç­‰å¾…è¯·æ±‚ä¸”æœªå¼€å¯è‡ªåŠ¨æ¥æ”¶)
                        else:
                            # ç§èŠæ–‡ä»¶å¤„ç†
                            await self._handle_private_file_v159(event, component)
                        
        except Exception as e:
            logger.error(f"[FileHandler-1.6.2] å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            logger.exception(e)
    
    async def _handle_private_file_v159(self, event: AstrMessageEvent, file_component):
        """å¤„ç†ç§èŠæ–‡ä»¶"""
        try:
            user_id = self._get_user_id(event)
            user_storage_path = os.path.join(self.storage_path, f"user_{user_id}")
            os.makedirs(user_storage_path, exist_ok=True)
            
            if self.debug_mode:
                logger.info(f"[1.6.2] å¤„ç†ç§èŠæ–‡ä»¶ - ç”¨æˆ·: {user_id}, å­˜å‚¨è·¯å¾„: {user_storage_path}")
            
            # æ£€æŸ¥ç”¨æˆ·æ–‡ä»¶æ•°é‡é™åˆ¶å¹¶æé†’åˆ é™¤
            removed_file = None
            if not self._check_file_limit(user_id, user_storage_path, self.max_files_per_user, "user"):
                record_file = os.path.join(user_storage_path, '.file_records.json')
                if os.path.exists(record_file):
                    with open(record_file, 'r', encoding='utf-8') as f:
                        try:
                            records = json.load(f)
                            if records:
                                removed_file = records[0].get('final_filename', 'æœªçŸ¥æ–‡ä»¶')
                        except:
                            pass
                
                if self.send_completion_message:
                    if self.send_completion_message:
                        msg = "âŒ æ–‡ä»¶å­˜å‚¨æ•°é‡å·²è¾¾ä¸Šé™!"
                        msg += "\nğŸ“¥ æ£€æµ‹åˆ°æ–‡ä»¶æ•°é‡è¶…é™,æ­£åœ¨è‡ªåŠ¨åˆ é™¤æœ€æ—§æ–‡ä»¶..." 
                        if removed_file:
                            msg += f"\nğŸ—‘ï¸ å·²è‡ªåŠ¨åˆ é™¤æœ€æ—§æ–‡ä»¶: {removed_file}"
                        msg += "\nâœ… æ–‡ä»¶åˆ é™¤å®Œæˆ,ç°åœ¨å¯ä»¥æ¥æ”¶æ–°æ–‡ä»¶äº†ã€‚"
                        await event.send(event.plain_result(msg))
            
            await self._process_file_download(event, file_component, user_storage_path, "user", user_id)
            
        except Exception as e:
            logger.error(f"[FileHandler-1.6.2] å¤„ç†ç§èŠæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            logger.exception(e)
    
    async def _handle_group_file_v159(self, event: AstrMessageEvent, file_component, group_id):
        """å¤„ç†ç¾¤èŠæ–‡ä»¶"""
        try:
            group_storage_path = os.path.join(self.storage_path, f"group_{group_id}")
            os.makedirs(group_storage_path, exist_ok=True)
            
            if self.debug_mode:
                logger.info(f"[1.6.2] å¤„ç†ç¾¤èŠæ–‡ä»¶ - ç¾¤: {group_id}, å­˜å‚¨è·¯å¾„: {group_storage_path}")
            
            # æ£€æŸ¥ç¾¤æ–‡ä»¶æ•°é‡é™åˆ¶å¹¶æé†’åˆ é™¤
            removed_file = None
            if not self._check_file_limit(group_id, group_storage_path, self.max_files_per_group, "group"):
                record_file = os.path.join(group_storage_path, '.file_records.json')
                if os.path.exists(record_file):
                    with open(record_file, 'r', encoding='utf-8') as f:
                        try:
                            records = json.load(f)
                            if records:
                                removed_file = records[0].get('final_filename', 'æœªçŸ¥æ–‡ä»¶')
                        except:
                            pass
                
                if self.send_completion_message:
                    if self.send_completion_message:
                        msg = "âŒ ç¾¤æ–‡ä»¶å­˜å‚¨æ•°é‡å·²è¾¾ä¸Šé™!"
                        msg += "\nğŸ“¥ æ£€æµ‹åˆ°ç¾¤æ–‡ä»¶æ•°é‡è¶…é™,æ­£åœ¨è‡ªåŠ¨åˆ é™¤æœ€æ—§æ–‡ä»¶..." 
                        if removed_file:
                            msg += f"\nğŸ—‘ï¸ å·²è‡ªåŠ¨åˆ é™¤æœ€æ—§æ–‡ä»¶: {removed_file}"
                        msg += "\nâœ… æ–‡ä»¶åˆ é™¤å®Œæˆ,ç°åœ¨å¯ä»¥æ¥æ”¶æ–°æ–‡ä»¶äº†ã€‚"
                        await event.send(event.plain_result(msg))
            
            await self._process_file_download(event, file_component, group_storage_path, "group", group_id)
            
        except Exception as e:
            logger.error(f"[FileHandler-1.6.2] å¤„ç†ç¾¤èŠæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            logger.exception(e)
    
    async def _process_file_download(self, event: AstrMessageEvent, file_component, storage_path, file_type, identifier):
        """å¤„ç†æ–‡ä»¶ä¸‹è½½çš„é€šç”¨æ–¹æ³•"""
        try:
            file_attrs = self._extract_file_attributes(file_component)
            original_name = self._extract_filename(file_attrs)
            file_url = self._extract_file_url(file_attrs)
            file_id = file_attrs.get('id') or file_attrs.get('file_id')
            file_size = file_attrs.get('size') or file_attrs.get('file_size', 0)
            
            if self.debug_mode:
                logger.info(f"[1.6.2] {file_type}æ–‡ä»¶ä¿¡æ¯ - åç§°: '{original_name}', å¤§å°: {file_size} bytes")
                logger.info(f"[1.6.2] æ–‡ä»¶URL: {file_url}")
                logger.info(f"[1.6.2] æ–‡ä»¶ID: {file_id}")
            
            if self.max_file_size_mb > 0:
                max_size_bytes = self.max_file_size_mb * 1024 * 1024
                if file_size <= 0 and file_url:
                    if 'large' in file_url.lower() or 'video' in file_url.lower():
                        file_size = max_size_bytes + 1
                
                if file_size > max_size_bytes:
                    size_mb = file_size / (1024 * 1024) if file_size > 0 else "æœªçŸ¥"
                    max_mb = self.max_file_size_mb
                    if self.send_completion_message:
                        await event.send(event.plain_result(
                            f"âŒ æ–‡ä»¶è¿‡å¤§æ— æ³•ä¸‹è½½!\n"
                            f"æ–‡ä»¶å¤§å°: {size_mb}MB\n"
                            f"å¤§å°é™åˆ¶: {max_mb}MB"
                        ))
                    return
            
            temp_filename = f"temp_file_{int(time.time())}"
            temp_filepath = os.path.join(storage_path, temp_filename)
            
            if file_url:
                download_success = await self._download_to_temp(file_url, temp_filepath)
                if download_success:
                    detected_type = self._detect_file_type_detailed(temp_filepath)
                    final_filename = self._smart_filename_handling(original_name, detected_type, temp_filepath)
                    final_filepath = os.path.join(storage_path, final_filename)
                    final_filepath = self._ensure_unique_filename(final_filepath)
                    
                    os.rename(temp_filepath, final_filepath)
                    if self.debug_mode:
                        logger.info(f"[1.6.2] æ–‡ä»¶å·²ä¿å­˜: {final_filepath}")
                    
                    record_info = {
                        'identifier': identifier,
                        'type': file_type,
                        'original_name': original_name,
                        'final_filename': final_filename,
                        'file_path': final_filepath,
                        'file_url': file_url,
                        'file_id': file_id,
                        'file_size': os.path.getsize(final_filepath),
                        'file_type': detected_type,
                        'receive_time': time.time(),
                        'sender': event.get_sender_name() if hasattr(event, 'get_sender_name') else 'unknown',
                        'platform': event.get_platform_name() if hasattr(event, 'get_platform_name') else 'unknown',
                        'download_status': 'success'
                    }
                    
                    record_file = os.path.join(storage_path, '.file_records.json')
                    self._save_record(record_file, record_info)
                    
                    if self.send_completion_message:
                        actual_size = os.path.getsize(final_filepath)
                        await self._send_completion_message(event, final_filename, final_filepath, actual_size, detected_type, original_name, file_type)
                        
                else:
                    if os.path.exists(temp_filepath):
                        os.remove(temp_filepath)
                    
                    record_info = {
                        'identifier': identifier,
                        'type': file_type,
                        'original_name': original_name,
                        'file_url': file_url,
                        'file_id': file_id,
                        'file_size': file_size,
                        'receive_time': time.time(),
                        'sender': event.get_sender_name() if hasattr(event, 'get_sender_name') else 'unknown',
                        'platform': event.get_platform_name() if hasattr(event, 'get_platform_name') else 'unknown',
                        'download_status': 'failed'
                    }
                    
                    record_file = os.path.join(storage_path, '.file_records.json')
                    self._save_record(record_file, record_info)
                    
                    if self.send_completion_message:
                        await event.send(event.plain_result(f"âŒ æ–‡ä»¶ {original_name} ä¸‹è½½å¤±è´¥!"))
            else:
                record_info = {
                    'identifier': identifier,
                    'type': file_type,
                    'original_name': original_name,
                    'file_url': file_url,
                    'file_id': file_id,
                    'file_size': file_size,
                    'receive_time': time.time(),
                    'sender': event.get_sender_name() if hasattr(event, 'get_sender_name') else 'unknown',
                    'platform': event.get_platform_name() if hasattr(event, 'get_platform_name') else 'unknown',
                    'download_status': 'no_url'
                }
                
                record_file = os.path.join(storage_path, '.file_records.json')
                self._save_record(record_file, record_info)
            
        except Exception as e:
            logger.error(f"[FileHandler-1.6.2] å¤„ç†æ–‡ä»¶ä¸‹è½½æ—¶å‡ºé”™: {e}")
            logger.exception(e)
    
    # ==================== ç§èŠæŒ‡ä»¤ ====================
    @filter.command("æŸ¥çœ‹æ–‡ä»¶", alias={'/fileinfo'})
    async def view_files(self, event: AstrMessageEvent):
        """æŸ¥çœ‹ç§èŠæ–‡ä»¶"""
        user_id = self._get_user_id(event)
        user_storage_path = os.path.join(self.storage_path, f"user_{user_id}")
        
        record_file = os.path.join(user_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("ğŸ“ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
                success_records = [r for r in records if r.get('download_status') == 'success']
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not success_records:
            await event.send(event.plain_result("ğŸ“ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        success_records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        msg_lines = [f"ğŸ“„ æ‚¨çš„ç§èŠæ–‡ä»¶ (å…±{len(success_records)}ä¸ªæ–‡ä»¶):"]
        msg_lines.append("åºå· | æ–‡ä»¶å | å¤§å° | ç±»å‹ | æ—¶é—´")
        msg_lines.append("-" * 50)
        
        for i, record in enumerate(success_records[:10], 1):
            filename = record.get('final_filename', 'unknown')[:20]
            size = self._format_file_size(record.get('file_size', 0))
            filetype = record.get('file_type', 'unknown')
            time_str = time.strftime('%m-%d %H:%M', time.localtime(record.get('receive_time', 0)))
            
            msg_lines.append(f"{i}. {filename} | {size} | {filetype} | {time_str}")
        
        if len(success_records) > 10:
            msg_lines.append(f"... è¿˜æœ‰{len(success_records) - 10}ä¸ªæ–‡ä»¶")
        
        msg_lines.append("\næŒ‡ä»¤: /å‘é€æ–‡ä»¶ <åºå·/æ–‡ä»¶å>  /åˆ é™¤æ–‡ä»¶ <åºå·/æ–‡ä»¶å>")
        
        await event.send(event.plain_result('\n'.join(msg_lines)))
    
    @filter.command("å‘é€æ–‡ä»¶")
    async def send_file(self, event: AstrMessageEvent, file_identifier: str = ""):
        """å‘é€ç§èŠæ–‡ä»¶"""
        if not file_identifier:
            await event.send(event.plain_result("âŒ è¯·æŒ‡å®šè¦å‘é€çš„æ–‡ä»¶\nç”¨æ³•: /å‘é€æ–‡ä»¶ <åºå·> æˆ– /å‘é€æ–‡ä»¶ <æ–‡ä»¶å>"))
            return
        
        user_id = self._get_user_id(event)
        user_storage_path = os.path.join(self.storage_path, f"user_{user_id}")
        
        record_file = os.path.join(user_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("âŒ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
                success_records = [r for r in records if r.get('download_status') == 'success']
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not success_records:
            await event.send(event.plain_result("âŒ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        success_records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        target_record = None
        
        if file_identifier.isdigit():
            index = int(file_identifier) - 1
            if 0 <= index < len(success_records):
                target_record = success_records[index]
            else:
                await event.send(event.plain_result(f"âŒ åºå·è¶…å‡ºèŒƒå›´ (1-{len(success_records)})"))
                return
        else:
            for record in success_records:
                if file_identifier in record.get('final_filename', ''):
                    target_record = record
                    break
            
            if not target_record:
                for record in success_records:
                    final_name = record.get('final_filename', '').lower()
                    orig_name = record.get('original_name', '').lower()
                    if file_identifier.lower() in final_name or file_identifier.lower() in orig_name:
                        target_record = record
                        break
            
            if not target_record:
                await event.send(event.plain_result(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {file_identifier}"))
                return
        
        file_path = target_record.get('file_path', '')
        if not file_path or not os.path.exists(file_path):
            await event.send(event.plain_result("âŒ æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤"))
            return
        
        filename = target_record.get('final_filename', 'file')
        
        try:
            import astrbot.api.message_components as Comp
            chain = [
                Comp.Plain(f"ğŸ“ æ–‡ä»¶: {filename}\n"),
                Comp.File(file=file_path, name=filename)
            ]
            await event.send(event.chain_result(chain))
            if self.debug_mode:
                logger.info(f"[1.6.2] å·²å‘é€æ–‡ä»¶: {filename}")
            
        except ImportError:
            if hasattr(event, 'file_result'):
                await event.send(event.file_result(file_path, filename))
            else:
                await event.send(event.plain_result(f"ğŸ“ æ–‡ä»¶: {filename}\nè·¯å¾„: {file_path}"))
    
    @filter.command("åˆ é™¤æ–‡ä»¶")
    async def delete_file(self, event: AstrMessageEvent, file_identifier: str = ""):
        """åˆ é™¤ç§èŠæ–‡ä»¶"""
        if not file_identifier:
            await event.send(event.plain_result("âŒ è¯·æŒ‡å®šè¦åˆ é™¤çš„æ–‡ä»¶\nç”¨æ³•: /åˆ é™¤æ–‡ä»¶ <åºå·> æˆ– /åˆ é™¤æ–‡ä»¶ <æ–‡ä»¶å>"))
            return
        
        user_id = self._get_user_id(event)
        user_storage_path = os.path.join(self.storage_path, f"user_{user_id}")
        
        record_file = os.path.join(user_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("âŒ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not records:
            await event.send(event.plain_result("âŒ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        target_record = None
        target_index = -1
        
        if file_identifier.isdigit():
            index = int(file_identifier) - 1
            if 0 <= index < len(records):
                target_record = records[index]
                target_index = index
            else:
                await event.send(event.plain_result(f"âŒ åºå·è¶…å‡ºèŒƒå›´ (1-{len(records)})"))
                return
        else:
            for i, record in enumerate(records):
                if file_identifier in record.get('final_filename', ''):
                    target_record = record
                    target_index = i
                    break
            
            if not target_record:
                for i, record in enumerate(records):
                    final_name = record.get('final_filename', '').lower()
                    orig_name = record.get('original_name', '').lower()
                    if file_identifier.lower() in final_name or file_identifier.lower() in orig_name:
                        target_record = record
                        target_index = i
                        break
            
            if not target_record:
                await event.send(event.plain_result(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {file_identifier}"))
                return
        
        file_path = target_record.get('file_path', '')
        filename = target_record.get('final_filename', 'unknown')
        
        if file_path and os.path.exists(file_path):
            try:
                os.remove(file_path)
                if self.debug_mode:
                    logger.info(f"[1.6.2] å·²åˆ é™¤æ–‡ä»¶: {file_path}")
            except Exception as e:
                logger.error(f"[1.6.2] åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                await event.send(event.plain_result(f"âŒ åˆ é™¤æ–‡ä»¶å¤±è´¥: {filename}"))
                return
        
        records.pop(target_index)
        with open(record_file, 'w', encoding='utf-8') as f:
            json.dump(records, f, ensure_ascii=False, indent=2)
        
        await event.send(event.plain_result(f"âœ… æ–‡ä»¶åˆ é™¤æˆåŠŸ!\næ–‡ä»¶å: {filename}"))
        if self.debug_mode:
            logger.info(f"[1.6.2] å·²åˆ é™¤æ–‡ä»¶è®°å½•: {filename}")
    
    @filter.command("é‡ç½®æ–‡ä»¶")
    async def reset_files(self, event: AstrMessageEvent):
        """é‡ç½®ç§èŠæ–‡ä»¶"""
        user_id = self._get_user_id(event)
        user_storage_path = os.path.join(self.storage_path, f"user_{user_id}")
        
        if not os.path.exists(user_storage_path):
            await event.send(event.plain_result("ğŸ“ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        # åˆ é™¤æ‰€æœ‰æ–‡ä»¶
        deleted_count = 0
        if os.path.exists(user_storage_path):
            for file in os.listdir(user_storage_path):
                file_path = os.path.join(user_storage_path, file)
                if os.path.isfile(file_path) and not file.startswith('.'):
                    try:
                        os.remove(file_path)
                        deleted_count += 1
                        if self.debug_mode:
                            logger.info(f"[1.6.2] å·²åˆ é™¤æ–‡ä»¶: {file_path}")
                    except Exception as e:
                        logger.error(f"[1.6.2] åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        # åˆ é™¤è®°å½•æ–‡ä»¶
        record_file = os.path.join(user_storage_path, '.file_records.json')
        if os.path.exists(record_file):
            try:
                os.remove(record_file)
                if self.debug_mode:
                    logger.info(f"[1.6.2] å·²åˆ é™¤è®°å½•æ–‡ä»¶: {record_file}")
            except Exception as e:
                logger.error(f"[1.6.2] åˆ é™¤è®°å½•æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        await event.send(event.plain_result(f"âœ… ç§èŠæ–‡ä»¶é‡ç½®å®Œæˆ!\nå…±åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶"))
        if self.debug_mode:
            logger.info(f"[1.6.2] ç”¨æˆ· {user_id} çš„ç§èŠæ–‡ä»¶å·²é‡ç½®")
    
    # ==================== ç¾¤èŠæŒ‡ä»¤ ====================
    @filter.command("æŸ¥çœ‹ç¾¤æ–‡ä»¶")
    async def view_group_files(self, event: AstrMessageEvent):
        """æŸ¥çœ‹ç¾¤æ–‡ä»¶ - ä»…ç¾¤èŠå¯ç”¨"""
        if not hasattr(event.message_obj, 'group_id') or not event.message_obj.group_id:
            await event.send(event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨"))
            return
        
        group_id = str(event.message_obj.group_id)
        group_storage_path = os.path.join(self.storage_path, f"group_{group_id}")
        
        record_file = os.path.join(group_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("ğŸ“ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
                success_records = [r for r in records if r.get('download_status') == 'success']
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not success_records:
            await event.send(event.plain_result("ğŸ“ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        success_records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        msg_lines = [f"ğŸ“„ ç¾¤ {group_id} çš„æ–‡ä»¶ (å…±{len(success_records)}ä¸ªæ–‡ä»¶):"]
        msg_lines.append("åºå· | æ–‡ä»¶å | å¤§å° | ç±»å‹ | æ—¶é—´")
        msg_lines.append("-" * 50)
        
        for i, record in enumerate(success_records[:10], 1):
            filename = record.get('final_filename', 'unknown')[:20]
            size = self._format_file_size(record.get('file_size', 0))
            filetype = record.get('file_type', 'unknown')
            time_str = time.strftime('%m-%d %H:%M', time.localtime(record.get('receive_time', 0)))
            
            msg_lines.append(f"{i}. {filename} | {size} | {filetype} | {time_str}")
        
        if len(success_records) > 10:
            msg_lines.append(f"... è¿˜æœ‰{len(success_records) - 10}ä¸ªæ–‡ä»¶")
        
        msg_lines.append("\næŒ‡ä»¤: /å‘é€ç¾¤æ–‡ä»¶ <åºå·/æ–‡ä»¶å>  /åˆ é™¤ç¾¤æ–‡ä»¶ <åºå·/æ–‡ä»¶å>")
        
        await event.send(event.plain_result('\n'.join(msg_lines)))
    
    @filter.command("å‘é€ç¾¤æ–‡ä»¶")
    async def send_group_file(self, event: AstrMessageEvent, file_identifier: str = ""):
        """å‘é€ç¾¤æ–‡ä»¶ - ä»…ç¾¤èŠå¯ç”¨"""
        if not file_identifier:
            await event.send(event.plain_result("âŒ è¯·æŒ‡å®šè¦å‘é€çš„æ–‡ä»¶\nç”¨æ³•: /å‘é€ç¾¤æ–‡ä»¶ <åºå·> æˆ– /å‘é€ç¾¤æ–‡ä»¶ <æ–‡ä»¶å>"))
            return
        
        if not hasattr(event.message_obj, 'group_id') or not event.message_obj.group_id:
            await event.send(event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨"))
            return
        
        group_id = str(event.message_obj.group_id)
        group_storage_path = os.path.join(self.storage_path, f"group_{group_id}")
        
        record_file = os.path.join(group_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("âŒ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
                success_records = [r for r in records if r.get('download_status') == 'success']
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not success_records:
            await event.send(event.plain_result("âŒ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        success_records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        target_record = None
        
        if file_identifier.isdigit():
            index = int(file_identifier) - 1
            if 0 <= index < len(success_records):
                target_record = success_records[index]
            else:
                await event.send(event.plain_result(f"âŒ åºå·è¶…å‡ºèŒƒå›´ (1-{len(success_records)})"))
                return
        else:
            for record in success_records:
                if file_identifier in record.get('final_filename', ''):
                    target_record = record
                    break
            
            if not target_record:
                for record in success_records:
                    final_name = record.get('final_filename', '').lower()
                    orig_name = record.get('original_name', '').lower()
                    if file_identifier.lower() in final_name or file_identifier.lower() in orig_name:
                        target_record = record
                        break
            
            if not target_record:
                await event.send(event.plain_result(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {file_identifier}"))
                return
        
        file_path = target_record.get('file_path', '')
        if not file_path or not os.path.exists(file_path):
            await event.send(event.plain_result("âŒ æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤"))
            return
        
        filename = target_record.get('final_filename', 'file')
        
        try:
            import astrbot.api.message_components as Comp
            chain = [
                Comp.Plain(f"ğŸ“ æ–‡ä»¶: {filename}\n"),
                Comp.File(file=file_path, name=filename)
            ]
            await event.send(event.chain_result(chain))
            if self.debug_mode:
                logger.info(f"[1.6.2] å·²å‘é€ç¾¤æ–‡ä»¶: {filename}")
            
        except ImportError:
            if hasattr(event, 'file_result'):
                await event.send(event.file_result(file_path, filename))
            else:
                await event.send(event.plain_result(f"ğŸ“ æ–‡ä»¶: {filename}\nè·¯å¾„: {file_path}"))
    
    @filter.command("åˆ é™¤ç¾¤æ–‡ä»¶")
    async def delete_group_file(self, event: AstrMessageEvent, file_identifier: str = ""):
        """åˆ é™¤ç¾¤æ–‡ä»¶ - ä»…ç¾¤èŠå¯ç”¨"""
        if not file_identifier:
            await event.send(event.plain_result("âŒ è¯·æŒ‡å®šè¦åˆ é™¤çš„æ–‡ä»¶\nç”¨æ³•: /åˆ é™¤ç¾¤æ–‡ä»¶ <åºå·> æˆ– /åˆ é™¤ç¾¤æ–‡ä»¶ <æ–‡ä»¶å>"))
            return
        
        if not hasattr(event.message_obj, 'group_id') or not event.message_obj.group_id:
            await event.send(event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨"))
            return
        
        group_id = str(event.message_obj.group_id)
        group_storage_path = os.path.join(self.storage_path, f"group_{group_id}")
        
        record_file = os.path.join(group_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("âŒ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not records:
            await event.send(event.plain_result("âŒ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        target_record = None
        target_index = -1
        
        if file_identifier.isdigit():
            index = int(file_identifier) - 1
            if 0 <= index < len(records):
                target_record = records[index]
                target_index = index
            else:
                await event.send(event.plain_result(f"âŒ åºå·è¶…å‡ºèŒƒå›´ (1-{len(records)})"))
                return
        else:
            for i, record in enumerate(records):
                if file_identifier in record.get('final_filename', ''):
                    target_record = record
                    target_index = i
                    break
            
            if not target_record:
                for i, record in enumerate(records):
                    final_name = record.get('final_filename', '').lower()
                    orig_name = record.get('original_name', '').lower()
                    if file_identifier.lower() in final_name or file_identifier.lower() in orig_name:
                        target_record = record
                        target_index = i
                        break
            
            if not target_record:
                await event.send(event.plain_result(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {file_identifier}"))
                return
        
        file_path = target_record.get('file_path', '')
        filename = target_record.get('final_filename', 'unknown')
        
        if file_path and os.path.exists(file_path):
            try:
                os.remove(file_path)
                if self.debug_mode:
                    logger.info(f"[1.6.2] å·²åˆ é™¤ç¾¤æ–‡ä»¶: {file_path}")
            except Exception as e:
                logger.error(f"[1.6.2] åˆ é™¤ç¾¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                await event.send(event.plain_result(f"âŒ åˆ é™¤ç¾¤æ–‡ä»¶å¤±è´¥: {filename}"))
                return
        
        records.pop(target_index)
        with open(record_file, 'w', encoding='utf-8') as f:
            json.dump(records, f, ensure_ascii=False, indent=2)
        
        await event.send(event.plain_result(f"âœ… ç¾¤æ–‡ä»¶åˆ é™¤æˆåŠŸ!\næ–‡ä»¶å: {filename}"))
        if self.debug_mode:
            logger.info(f"[1.6.2] å·²åˆ é™¤ç¾¤æ–‡ä»¶è®°å½•: {filename}")
    
    @filter.command("é‡ç½®ç¾¤æ–‡ä»¶")
    async def reset_group_files(self, event: AstrMessageEvent):
        """é‡ç½®ç¾¤æ–‡ä»¶ - ä»…ç¾¤èŠå¯ç”¨"""
        if not hasattr(event.message_obj, 'group_id') or not event.message_obj.group_id:
            await event.send(event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨"))
            return
        
        group_id = str(event.message_obj.group_id)
        group_storage_path = os.path.join(self.storage_path, f"group_{group_id}")
        
        if not os.path.exists(group_storage_path):
            await event.send(event.plain_result("ğŸ“ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        # åˆ é™¤æ‰€æœ‰æ–‡ä»¶
        deleted_count = 0
        if os.path.exists(group_storage_path):
            for file in os.listdir(group_storage_path):
                file_path = os.path.join(group_storage_path, file)
                if os.path.isfile(file_path) and not file.startswith('.'):
                    try:
                        os.remove(file_path)
                        deleted_count += 1
                        if self.debug_mode:
                            logger.info(f"[1.6.2] å·²åˆ é™¤ç¾¤æ–‡ä»¶: {file_path}")
                    except Exception as e:
                        logger.error(f"[1.6.2] åˆ é™¤ç¾¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        # åˆ é™¤è®°å½•æ–‡ä»¶
        record_file = os.path.join(group_storage_path, '.file_records.json')
        if os.path.exists(record_file):
            try:
                os.remove(record_file)
                if self.debug_mode:
                    logger.info(f"[1.6.2] å·²åˆ é™¤ç¾¤è®°å½•æ–‡ä»¶: {record_file}")
            except Exception as e:
                logger.error(f"[1.6.2] åˆ é™¤ç¾¤è®°å½•æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        await event.send(event.plain_result(f"âœ… ç¾¤ {group_id} æ–‡ä»¶é‡ç½®å®Œæˆ!\nå…±åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶"))
        if self.debug_mode:
            logger.info(f"[1.6.2] ç¾¤ {group_id} çš„æ–‡ä»¶å·²é‡ç½®")
    
    @filter.command("æ¥æ”¶ç¾¤æ–‡ä»¶")
    async def receive_group_file(self, event: AstrMessageEvent):
        """æ¥æ”¶ç¾¤æ–‡ä»¶ - æ”¹è¿›ç‰ˆé€»è¾‘"""
        if not hasattr(event.message_obj, 'group_id') or not event.message_obj.group_id:
            await event.send(event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨"))
            return
        
        if self.auto_receive_group_files:
            await event.send(event.plain_result("âœ… è‡ªåŠ¨æ¥æ”¶ç¾¤æ–‡ä»¶å·²å¼€å¯,æ— éœ€æ‰‹åŠ¨æ¥æ”¶"))
            return
        
        group_id = str(event.message_obj.group_id)
        user_id = self._get_user_id(event)
        
        # è®¾ç½®ç­‰å¾…æ¥æ”¶çŠ¶æ€
        expire_time = time.time() + self.group_file_receive_timeout
        self.pending_group_receives[group_id][user_id] = expire_time
        
        timeout_msg = f"{self.group_file_receive_timeout}"
        await event.send(event.plain_result(
            f"ğŸ’¡ è¯·åœ¨ {timeout_msg} ç§’å†…å‘é€è¦æ¥æ”¶çš„æ–‡ä»¶\n"
            f"æ”¯æŒç›´æ¥å‘é€æˆ–å¼•ç”¨æ–‡ä»¶æ¶ˆæ¯\n"
            f"è¶…æ—¶å°†è‡ªåŠ¨å–æ¶ˆæ¥æ”¶"
        ))
        
        if self.debug_mode:
            logger.info(f"[1.6.2] ç¾¤ {group_id} ç”¨æˆ· {user_id} å¼€å§‹ç­‰å¾…æ–‡ä»¶æ¥æ”¶,è¶…æ—¶æ—¶é—´: {timeout_msg}ç§’")
    
    def _get_user_id(self, event: AstrMessageEvent):
        """è·å–ç”¨æˆ·ID"""
        try:
            if hasattr(event, 'message_obj') and event.message_obj:
                message_obj = event.message_obj
                if hasattr(message_obj, 'sender') and message_obj.sender:
                    user_id = getattr(message_obj.sender, 'user_id', None)
                    if user_id:
                        return str(user_id)
            
            sender_name = event.get_sender_name() if hasattr(event, 'get_sender_name') else 'unknown'
            platform = event.get_platform_name() if hasattr(event, 'get_platform_name') else 'unknown'
            return f"{sender_name}_{platform}"
            
        except Exception as e:
            logger.error(f"[1.6.2] è·å–ç”¨æˆ·IDæ—¶å‡ºé”™: {e}")
            return "unknown_user"
    

    def _check_file_limit(self, entity_id, storage_path, max_files, entity_type="user"):
        """é€šç”¨æ–‡ä»¶æ•°é‡é™åˆ¶æ£€æŸ¥"""
        try:
            record_file = os.path.join(storage_path, '.file_records.json')
            if not os.path.exists(record_file):
                return True

            with open(record_file, 'r', encoding='utf-8') as f:
                try:
                    records = json.load(f)
                    success_records = [r for r in records if r.get('download_status') == 'success']

                    if len(success_records) >= max_files:
                        entity_desc = "ç”¨æˆ·" if entity_type == "user" else "ç¾¤"
                        logger.warning(f"[1.6.2] æ£€æµ‹åˆ°{entity_desc}æ–‡ä»¶æ•°é‡å·²è¾¾ä¸Šé™({max_files})")
                        logger.info(f"[1.6.2] å‡†å¤‡åˆ é™¤æœ€æ—§æ–‡ä»¶ä»¥è…¾å‡ºç©ºé—´")
                        logger.warning(f"[1.6.2] {entity_desc}æ–‡ä»¶æ•°é‡å·²è¾¾ä¸Šé™({max_files}),å°†è‡ªåŠ¨åˆ é™¤æœ€æ—§æ–‡ä»¶")
                        self._remove_oldest_file(success_records, storage_path, record_file)
                        logger.info(f"[1.6.2] å·²è‡ªåŠ¨åˆ é™¤æœ€æ—§æ–‡ä»¶,ä¸ºæ–°æ–‡ä»¶è…¾å‡ºç©ºé—´")
                        logger.info(f"[1.6.2] æ–‡ä»¶åˆ é™¤å®Œæˆ,å…è®¸æ¥æ”¶æ–°æ–‡ä»¶")
                        return True
                    else:
                        return True

                except:
                    return True

        except Exception as e:
            entity_desc = "ç”¨æˆ·" if entity_type == "user" else "ç¾¤"
            logger.error(f"[1.6.2] æ£€æŸ¥{entity_desc}æ–‡ä»¶é™åˆ¶æ—¶å‡ºé”™: {e}")
            return True
            # [v1.6.2] åˆ é™¤æ—§æ–‡ä»¶åç»§ç»­å¤„ç†æ–°æ–‡ä»¶\n
    def _remove_oldest_file(self, records, storage_path, record_file):
        """åˆ é™¤æœ€æ—§çš„æ–‡ä»¶"""
        try:
            records.sort(key=lambda x: x.get('receive_time', 0))
            oldest_record = records[0]
            
            file_path = oldest_record.get('file_path', '')
            if file_path and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    if self.debug_mode:
                        logger.info(f"[1.6.2] å·²åˆ é™¤æœ€æ—§æ–‡ä»¶: {file_path}")
                except Exception as e:
                    logger.error(f"[1.6.2] åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            
            remaining_records = records[1:]
            with open(record_file, 'w', encoding='utf-8') as f:
                json.dump(remaining_records, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"[1.6.2] åˆ é™¤æœ€æ—§æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def _smart_filename_handling(self, original_name, detected_type, file_path):
        """æ™ºèƒ½æ–‡ä»¶åå¤„ç†"""
        try:
            if (original_name and 
                original_name not in ['unknown_file', 'qqdownloadftnv5'] and
                len(original_name) > 5 and
                '.' in original_name):
                
                original_ext = os.path.splitext(original_name)[1].lower()
                detected_ext = detected_type.lower()
                
                if (original_ext == detected_ext or 
                    (original_ext in ['.docx', '.doc'] and detected_ext in ['.docx', '.doc']) or
                    (original_ext in ['.xlsx', '.xls'] and detected_ext in ['.xlsx', '.xls']) or
                    (original_ext in ['.pptx', '.ppt'] and detected_ext in ['.pptx', '.ppt'])):
                    
                    if self.debug_mode:
                        logger.info(f"[1.6.2] ä½¿ç”¨æœ‰æ•ˆçš„åŸå§‹æ–‡ä»¶å: {original_name}")
                    return self._sanitize_filename(original_name)
            
            name_without_ext = os.path.splitext(original_name)[0]
            if name_without_ext and name_without_ext not in ['unknown_file', 'qqdownloadftnv5']:
                final_name = f"{name_without_ext}{detected_type}"
            else:
                timestamp = int(time.time())
                final_name = f"file_{timestamp}{detected_type}"
            
            return self._sanitize_filename(final_name)
            
        except Exception as e:
            logger.error(f"[1.6.2] æ™ºèƒ½æ–‡ä»¶åå¤„ç†å‡ºé”™: {e}")
            timestamp = int(time.time())
            return f"file_{timestamp}{detected_type}"
    
    async def _send_completion_message(self, event: AstrMessageEvent, filename, filepath, filesize, filetype, original_name, file_type):
        """å‘é€å®Œæˆæ¶ˆæ¯"""
        try:
            size_str = self._format_file_size(filesize)
            
            if original_name in ['unknown_file', 'qqdownloadftnv5'] or not original_name:
                completion_msg = f"""âœ… {'ç¾¤' if file_type == 'group' else 'ç§èŠ'}æ–‡ä»¶æ¥æ”¶æˆåŠŸ!
æ–‡ä»¶å: {filename}
å¤§å°: {size_str}
ç±»å‹: {filetype}
è·¯å¾„: {filepath}

ğŸ’¡ æç¤º: ç”±äºç¯å¢ƒé™åˆ¶,åŸå§‹æ–‡ä»¶åæ— æ³•è·å–
ç³»ç»Ÿå·²ä¸ºæ‚¨ç”Ÿæˆæ–°çš„æ–‡ä»¶å: {filename}"""
            else:
                completion_msg = f"""âœ… {'ç¾¤' if file_type == 'group' else 'ç§èŠ'}æ–‡ä»¶æ¥æ”¶æˆåŠŸ!
åŸå§‹å: {original_name}
ä¿å­˜ä¸º: {filename}
å¤§å°: {size_str}
ç±»å‹: {filetype}
è·¯å¾„: {filepath}"""
            
            await event.send(event.plain_result(completion_msg))
            if self.debug_mode:
                logger.info(f"[1.6.2] å·²å‘é€å®Œæˆæ¶ˆæ¯: {filename}")
            # è‡ªåŠ¨è¯»å–æ–‡æœ¬æ–‡ä»¶å†…å®¹åŠŸèƒ½
            if self.auto_read_content:
                # æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶
                try:
                    file_size = os.path.getsize(filepath)
                    max_size = self.max_auto_read_size

                    if file_size <= max_size:
                        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬æ–‡ä»¶
                        if self._is_text_file_safe(filepath):
                            # è¯»å–æ–‡ä»¶å†…å®¹
                            content = self._read_text_file_safely(filepath)
                            if content:
                                logger.info(f"[AutoRead] è‡ªåŠ¨è¯»å–æ–‡æœ¬æ–‡ä»¶å†…å®¹: {filename}")
                                
                                # æ ¸å¿ƒåŠŸèƒ½:å°†æ–‡ä»¶å†…å®¹ä½œä¸ºç”¨æˆ·æ¶ˆæ¯å¤„ç†,è§¦å‘AIè‡ªç„¶å›å¤
                                try:
                                    clean_content = content.strip()
                                    if len(clean_content) > self.max_auto_read_size:
                                        clean_content = clean_content[:self.max_auto_read_size] + "\n[å†…å®¹å·²æˆªæ–­,åŸæ–‡è¿‡é•¿]"
                                    
                                    await self._handle_file_as_user_message(event, clean_content, filename)
                                    logger.info(f"[AutoRead-AI] å·²æäº¤AIå¤„ç†æ–‡ä»¶å†…å®¹")
                                except Exception as ai_error:
                                    logger.error(f"[AutoRead-AI] AIå¤„ç†å¤±è´¥: {ai_error}")
                                    # AIå¤„ç†å¤±è´¥æ—¶çš„é™çº§å¤„ç†
                                    try:
                                        await self._send_reply(event, f"ğŸ“„ æ–‡ä»¶å†…å®¹:\n{content[:500]}...")
                                    except:
                                        try:
                                            from astrbot.api.event import MessageChain
                                            message_chain = MessageChain().message(f"ğŸ“„ æ–‡ä»¶å·²è¯»å–å¹¶æäº¤AIåˆ†æ")
                                            await self.context.send_message(event.unified_msg_origin, message_chain)
                                        except:
                                            pass
                            else:
                                logger.info(f"[AutoRead] æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–è¯»å–å¤±è´¥")
                    else:
                        logger.info(f"[AutoRead] æ–‡ä»¶è¿‡å¤§,è·³è¿‡è‡ªåŠ¨è¯»å–: {file_size} bytes > {max_size} bytes")
                except Exception as size_error:
                    logger.error(f"[AutoRead] æ£€æŸ¥æ–‡ä»¶æ—¶å‡ºé”™: {size_error}")
        except Exception as e:
            logger.error(f"[1.6.2] å‘é€å®Œæˆæ¶ˆæ¯å‡ºé”™: {e}")
    
    def _format_file_size(self, size_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
        else:
            return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"
    
    def _detect_file_type_detailed(self, filepath):
        """å¢å¼ºçš„æ–‡ä»¶ç±»å‹æ£€æµ‹ - ä¿®å¤PPTXè¯†åˆ«é—®é¢˜å’Œæ–‡æœ¬æ–‡ä»¶è¯†åˆ«é—®é¢˜
        
        æ”¯æŒäº”å±‚æ£€æµ‹æœºåˆ¶:
        1. filetypeåº“æ£€æµ‹
        2. æ–‡æœ¬æ–‡ä»¶æ£€æµ‹
        3. æ–‡ä»¶å¤´ç‰¹å¾åˆ†æ
        4. äºŒè¿›åˆ¶æ–‡ä»¶åˆ¤æ–­
        5. é»˜è®¤ç±»å‹è¿”å›
        """
        import os
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(filepath):
            return ".bin"
        
        # [v1.6.2] ç¬¬ä¸€å±‚æ£€æµ‹:ä½¿ç”¨filetypeåº“(å¦‚æœå¯ç”¨)
        try:
            import filetype
            kind = filetype.guess(filepath)
            if kind is not None:
                detected_ext = f".{kind.extension}"
                if self.debug_mode:
                    logger.info(f"[1.6.2] filetypeåº“æ£€æµ‹ç»“æœ: {kind.mime} -> {detected_ext}")
                # ç‰¹åˆ«å¤„ç†Officeæ–‡ä»¶ä»¥ç¡®ä¿å‡†ç¡®æ€§
                if detected_ext in ['.docx', '.xlsx', '.pptx', '.doc', '.xls', '.ppt']:
                    return detected_ext
                # å¯¹äºå·²çŸ¥æ–‡æœ¬ç±»å‹,ç›´æ¥è¿”å›
                text_types = ['.txt', '.py', '.c', '.cpp', '.h', '.java', '.js', '.html', '.css', '.xml', '.json', '.yaml', '.yml', '.md', '.csv', '.log']
                if detected_ext in text_types:
                    return detected_ext
        except ImportError:
            if self.debug_mode:
                logger.debug("[1.6.2] filetypeåº“æœªå®‰è£…,è·³è¿‡ç¬¬ä¸€å±‚æ£€æµ‹")
        except Exception as e:
            if self.debug_mode:
                logger.warning(f"[1.6.2] filetypeåº“æ£€æµ‹å¼‚å¸¸: {e}")
        
        # [v1.6.2] ç¬¬äºŒå±‚æ£€æµ‹:æ–‡æœ¬æ–‡ä»¶æ£€æµ‹
        try:
            is_text, encoding = self._is_text_file_safe(filepath)
            if is_text:
                if self.debug_mode:
                    logger.info(f"[1.6.2] æ£€æµ‹åˆ°æ–‡æœ¬æ–‡ä»¶,ç¼–ç : {encoding}")
                return ".txt"
        except Exception as e:
            if self.debug_mode:
                logger.warning(f"[1.6.2] æ–‡æœ¬æ–‡ä»¶æ£€æµ‹å¼‚å¸¸: {e}")
        
        # [v1.6.2] ç¬¬ä¸‰å±‚æ£€æµ‹:æ–‡ä»¶å¤´ç‰¹å¾åˆ†æ
        try:
            with open(filepath, 'rb') as f:
                header = f.read(1024)  # è¯»å–å‰1024å­—èŠ‚
            
            # æ£€æŸ¥å¸¸è§çš„æ–‡ä»¶å¤´ç‰¹å¾
            if header.startswith(b'\x89PNG\r\n\x1a\n'):
                return ".png"
            elif header.startswith(b'\xff\xd8\xff'):
                return ".jpg"
            elif header.startswith(b'GIF87a') or header.startswith(b'GIF89a'):
                return ".gif"
            elif header.startswith(b'%PDF'):
                return ".pdf"
            elif header.startswith(b'PK'):
                # ZIPæ–‡ä»¶,å¯èƒ½æ˜¯Officeæ–‡æ¡£
                return ".zip"
            elif header.startswith(b'\x1f\x8b'):
                return ".gz"
            elif header.startswith(b'Rar!'):
                return ".rar"
        except Exception as e:
            if self.debug_mode:
                logger.warning(f"[1.6.2] æ–‡ä»¶å¤´æ£€æµ‹å¼‚å¸¸: {e}")
        
        # [v1.6.2] ç¬¬å››å±‚æ£€æµ‹:äºŒè¿›åˆ¶æ–‡ä»¶åˆ¤æ–­
        try:
            with open(filepath, 'rb') as f:
                sample = f.read(1024)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤§é‡ä¸å¯æ‰“å°å­—ç¬¦
            if sample:
                non_printable = sum(1 for byte in sample if byte < 32 and byte not in [9, 10, 13])
                printable_ratio = 1 - (non_printable / len(sample))
                
                if printable_ratio < 0.7:  # å¦‚æœå¯æ‰“å°å­—ç¬¦å°‘äº70%,è®¤ä¸ºæ˜¯äºŒè¿›åˆ¶æ–‡ä»¶
                    if self.debug_mode:
                        logger.info(f"[1.6.2] æ£€æµ‹åˆ°äºŒè¿›åˆ¶æ–‡ä»¶,å¯æ‰“å°å­—ç¬¦æ¯”ä¾‹: {printable_ratio:.2f}")
                    return ".bin"
        except Exception as e:
            if self.debug_mode:
                logger.warning(f"[1.6.2] äºŒè¿›åˆ¶æ–‡ä»¶æ£€æµ‹å¼‚å¸¸: {e}")
        
        # [v1.6.2] ç¬¬äº”å±‚æ£€æµ‹:é»˜è®¤è¿”å›ç­–ç•¥
        # å¦‚æœå‰é¢éƒ½æ— æ³•ç¡®å®š,ä¼˜å…ˆè¿”å›.txtè€Œä¸æ˜¯.bin
        if self.debug_mode:
            logger.info("[1.6.2] æ— æ³•ç¡®å®šæ–‡ä»¶ç±»å‹,è¿”å›é»˜è®¤.txt")
        return ".txt"

    def _extract_file_attributes(self, file_component):
        """æå–æ–‡ä»¶å±æ€§"""
        attrs = {}
        try:
            attr_names = [attr for attr in dir(file_component) if not attr.startswith('_')]
            for attr in attr_names:
                try:
                    value = getattr(file_component, attr)
                    if isinstance(value, (str, int, float, bool, type(None))):
                        attrs[attr] = value
                except:
                    pass
        except Exception as e:
            logger.error(f"[1.6.2] æå–å±æ€§æ—¶å‡ºé”™: {e}")
        return attrs
    
    def _extract_filename(self, file_attrs):
        """æå–æ–‡ä»¶å"""
        filename = (file_attrs.get('name') or 
                file_attrs.get('filename') or 
                file_attrs.get('file_name') or 
                'unknown_file')
        result = self._sanitize_filename(filename) if filename else 'unknown_file'
        if self.debug_mode:
            logger.info(f"[1.6.2] æå–æ–‡ä»¶å: '{filename}' -> '{result}'")
        return result
    
    def _extract_file_url(self, file_attrs):
        """æå–æ–‡ä»¶URL"""
        url = (file_attrs.get('url') or 
            file_attrs.get('file_url') or 
            file_attrs.get('path') or 
            file_attrs.get('file_path'))
        if self.debug_mode and url:
            logger.info(f"[1.6.2] æå–æ–‡ä»¶URL: {url[:100]}...")  # åªæ˜¾ç¤ºå‰100å­—ç¬¦
        return url
    
    async def _download_to_temp(self, url, temp_path):
        """ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶"""
        try:
            if self.debug_mode:
                logger.info(f"[1.6.2] å¼€å§‹ä¸‹è½½: {url[:100]}...")  # åªæ˜¾ç¤ºå‰100å­—ç¬¦
            
            timeout = aiohttp.ClientTimeout(total=120)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        with open(temp_path, 'wb') as f:
                            async for chunk in response.content.iter_chunked(8192):
                                f.write(chunk)
                        if self.debug_mode:
                            logger.info(f"[1.6.2] ä¸‹è½½æˆåŠŸ: {temp_path}")
                        return True
                    else:
                        if self.debug_mode:
                            logger.error(f"[1.6.2] ä¸‹è½½å¤±è´¥ HTTP {response.status}")
                        return False
                        
        except Exception as e:
            if self.debug_mode:
                logger.error(f"[1.6.2] ä¸‹è½½å‡ºé”™: {e}")
            return False
    
    async def _cleanup_task(self):
        """è‡ªåŠ¨æ¸…ç†ä»»åŠ¡"""
        while True:
            try:
                if self.auto_cleanup_enabled:
                    await asyncio.sleep(3600)
                    self._cleanup_expired_files()
            except Exception as e:
                logger.error(f"[1.6.2] æ¸…ç†ä»»åŠ¡å‡ºé”™: {e}")
                await asyncio.sleep(60)
    
    def _cleanup_expired_files(self):
        """æ¸…ç†è¿‡æœŸæ–‡ä»¶"""
        try:
            if not os.path.exists(self.storage_path):
                return
                
            for item in os.listdir(self.storage_path):
                item_path = os.path.join(self.storage_path, item)
                if os.path.isdir(item_path):
                    record_file = os.path.join(item_path, '.file_records.json')
                    if not os.path.exists(record_file):
                        continue
                    
                    with open(record_file, 'r', encoding='utf-8') as f:
                        try:
                            records = json.load(f)
                        except:
                            records = []
                    
                    current_time = time.time()
                    expired_records = []
                    valid_records = []
                    
                    for record in records:
                        receive_time = record.get('receive_time', 0)
                        file_path = record.get('file_path', '')
                        
                        if current_time - receive_time > self.cleanup_days * 24 * 3600:
                            expired_records.append(record)
                            if file_path and os.path.exists(file_path):
                                try:
                                    os.remove(file_path)
                                    if self.debug_mode:
                                        logger.info(f"[1.6.2] å·²åˆ é™¤è¿‡æœŸæ–‡ä»¶: {file_path}")
                                except Exception as e:
                                    logger.error(f"[1.6.2] åˆ é™¤æ–‡ä»¶å‡ºé”™: {e}")
                        else:
                            valid_records.append(record)
                    
                    with open(record_file, 'w', encoding='utf-8') as f:
                        json.dump(valid_records, f, ensure_ascii=False, indent=2)
                    
                    if expired_records and self.debug_mode:
                        logger.info(f"[1.6.2] ç›®å½• {item} æ¸…ç†äº† {len(expired_records)} ä¸ªè¿‡æœŸæ–‡ä»¶")
                        
        except Exception as e:
            logger.error(f"[1.6.2] æ¸…ç†è¿‡æœŸæ–‡ä»¶å‡ºé”™: {e}")
    
    def _ensure_unique_filename(self, filepath):
        """ç¡®ä¿æ–‡ä»¶åå”¯ä¸€"""
        counter = 1
        name, ext = os.path.splitext(filepath)
        
        while os.path.exists(filepath):
            filepath = f"{name}_{counter}{ext}"
            counter += 1
            if counter > 1000:
                filepath = f"{name}_{int(time.time())}_{counter}{ext}"
                break
        
        if self.debug_mode and counter > 1:
            logger.info(f"[1.6.2] æ–‡ä»¶åå†²çª,ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å: {filepath}")
        
        return filepath
    
    def _sanitize_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶å"""
        if not filename:
            return 'unnamed_file.bin'
        
        illegal_chars = '<>:"/\\|?*'
        for char in illegal_chars:
            filename = filename.replace(char, '_')
        
        filename = ''.join(char for char in filename if ord(char) >= 32)
        filename = re.sub(r'_+', '_', filename)
        filename = filename.strip('_. ')
        
        return filename if filename else 'unnamed_file.bin'
    
    async def _save_record(self, record_file, record_info):
        """ä¿å­˜è®°å½•"""
        try:
            records = []
            if os.path.exists(record_file):
                with open(record_file, 'r', encoding='utf-8') as f:
                    try:
                        records = json.load(f)
                    except:
                        records = []
            
            records.append(record_info)
            
            with open(record_file, 'w', encoding='utf-8') as f:
                json.dump(records, f, ensure_ascii=False, indent=2)
                
            if self.debug_mode:
                logger.info(f"[1.6.2] è®°å½•å·²ä¿å­˜")
                
        except Exception as e:
            logger.error(f"[1.6.2] ä¿å­˜è®°å½•å‡ºé”™: {e}")
    
    @filter.command("filestatus")
    async def file_status(self, event: AstrMessageEvent):
        """æŸ¥çœ‹æ’ä»¶çŠ¶æ€"""
        status_msg = f"""ğŸ“ æ–‡ä»¶å¤„ç†å™¨çŠ¶æ€ (v1.6.2):
å­˜å‚¨è·¯å¾„: {self.storage_path}
è‡ªåŠ¨æ¸…ç†: {'âœ… å¯ç”¨' if self.auto_cleanup_enabled else 'âŒ ç¦ç”¨'}
æ¸…ç†å¤©æ•°: {self.cleanup_days}å¤©
å®Œæˆæ¶ˆæ¯: {'âœ… å¯ç”¨' if self.send_completion_message else 'âŒ ç¦ç”¨'}
ç§èŠæ–‡ä»¶é™åˆ¶: {self.max_files_per_user}ä¸ª/ç”¨æˆ·
ç¾¤èŠæ–‡ä»¶é™åˆ¶: {self.max_files_per_group}ä¸ª/ç¾¤
æ–‡ä»¶å¤§å°é™åˆ¶: {self.max_file_size_mb}MB
ç¾¤èŠç™½åå•: {'å…¨éƒ¨ç¾¤' if not self.group_whitelist else self.group_whitelist}
è‡ªåŠ¨æ¥æ”¶ç¾¤æ–‡ä»¶: {'âœ… å¯ç”¨' if self.auto_receive_group_files else 'âŒ ç¦ç”¨'}
æ¥æ”¶è¶…æ—¶æ—¶é—´: {self.group_file_receive_timeout}ç§’
LLMå·¥å…·æ”¯æŒ: {'âœ… å¯ç”¨' if LLM_TOOL_SUPPORT else 'âŒ ç¦ç”¨'}
è°ƒè¯•æ¨¡å¼: {'âœ… å¼€å¯' if self.debug_mode else 'âŒ å…³é—­'}"""

    def _is_text_file(self, file_path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬æ–‡ä»¶"""
        text_extensions = {
            ".txt", ".py", ".c", ".cpp", ".h", ".java", ".js", ".html", 
            ".css", ".xml", ".json", ".yaml", ".yml", ".md", ".log", ".csv"
        }
        
        _, ext = os.path.splitext(file_path.lower())
        return ext in text_extensions

    def _is_text_file_safe(self, filepath):
        """å®‰å…¨åœ°æ£€æµ‹æ˜¯å¦ä¸ºæ–‡æœ¬æ–‡ä»¶"""
        import os
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(filepath):
            return False, None
        
        encodings = ['utf-8', 'gbk', 'gb2312', 'latin1']
        
        for encoding in encodings:
            try:
                with open(filepath, 'r', encoding=encoding) as f:
                    # è¯»å–å‰å‡ KBæ¥æ£€æµ‹
                    sample = f.read(4096)
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿‡å¤šçš„æ§åˆ¶å­—ç¬¦
                    if sample:  # ç¡®ä¿sampleä¸ä¸ºç©º
                        control_chars = sum(1 for c in sample if ord(c) < 32 and c not in '\t\n\r')
                        if control_chars / len(sample) > 0.3:
                            continue  # æ§åˆ¶å­—ç¬¦è¿‡å¤š,å¯èƒ½ä¸æ˜¯æ–‡æœ¬æ–‡ä»¶
                    return True, encoding
            except UnicodeDecodeError:
                continue
            except Exception:
                continue
        
        return False, None

        
        for encoding in encodings:
            try:
                with open(file_path, "r", encoding=encoding) as f:
                    content = f.read()
                    # é™åˆ¶å†…å®¹é•¿åº¦ä»¥é¿å…è¿‡é•¿æ¶ˆæ¯
                    if len(content) > 2000:
                        content = content[:2000] + "\n[å†…å®¹å·²æˆªæ–­,åŸæ–‡è¿‡é•¿]"
                    return content
            except UnicodeDecodeError:
                continue
            except Exception as e:
                logger.error(f"[AutoRead] è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                return ""
        
        logger.warning(f"[AutoRead] æ— æ³•è§£ç æ–‡ä»¶: {file_path}")
        return ""

    def _read_text_file_safely(self, file_path: str) -> str:
        """å®‰å…¨åœ°è¯»å–æ–‡æœ¬æ–‡ä»¶å†…å®¹"""
        encodings = ["utf-8", "gbk", "gb2312", "latin1"]
        
        for encoding in encodings:
            try:
                with open(file_path, "r", encoding=encoding) as f:
                    content = f.read()
                    # é™åˆ¶å†…å®¹é•¿åº¦ä»¥é¿å…è¿‡é•¿æ¶ˆæ¯
                    if len(content) > self.max_auto_read_size:
                        content = content[:self.max_auto_read_size] + "\n[å†…å®¹å·²æˆªæ–­,åŸæ–‡è¿‡é•¿]"
                    return content
            except UnicodeDecodeError:
                continue
            except Exception as e:
                logger.error(f"[AutoRead] è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                return ""
        
        logger.warning(f"[AutoRead] æ— æ³•è§£ç æ–‡ä»¶: {file_path}")
        return ""

AutoFileHandlerPlugin = PluginMain
