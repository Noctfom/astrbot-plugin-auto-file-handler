# -*- coding: utf-8 -*-
"""
AstrBotè‡ªåŠ¨æ–‡ä»¶å¤„ç†å™¨æ’ä»¶ - 1.5.12ç‰ˆæœ¬
å½»åº•ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯å’Œæ·»åŠ è°ƒè¯•å¼€å…³
"""

from astrbot.api.star import Star, register
from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api import logger, AstrBotConfig
import os
import time
import asyncio
import aiohttp
import json
from urllib.parse import urlparse
import re
import zipfile
import tarfile
from collections import defaultdict

# LLMå·¥å…·æ”¯æŒ
try:
    from pydantic import Field
    from pydantic.dataclasses import dataclass
    from astrbot.core.agent.run_context import ContextWrapper
    from astrbot.core.agent.tool import FunctionTool, ToolExecResult
    from astrbot.core.astr_agent_context import AstrAgentContext
    LLM_TOOL_SUPPORT = True
except ImportError:
    LLM_TOOL_SUPPORT = False
    logger.info("[FileHandler-1.5.12] LLMå·¥å…·æ”¯æŒä¸å¯ç”¨")

# å…¨å±€å­˜å‚¨æ’ä»¶å®ä¾‹ï¼Œä¾›LLMå·¥å…·è®¿é—®
_plugin_instance = None

# LLMå·¥å…·å®šä¹‰ - å½»åº•ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯
if LLM_TOOL_SUPPORT:
    @dataclass
    class FileListTool(FunctionTool[AstrAgentContext]):
        name: str = "list_user_files"
        description: str = "å½“ç”¨æˆ·è¯¢é—®å…³äºä»–ä»¬å‘é€ç»™æœºå™¨äººçš„æ–‡ä»¶æ—¶ï¼Œä½¿ç”¨æ­¤å·¥å…·åˆ—å‡ºç”¨æˆ·çš„æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡ä»¶åã€è·¯å¾„ã€å¤§å°ç­‰"
        parameters: dict = Field(
            default_factory=lambda: {
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                        "description": "ç”¨æˆ·çš„å”¯ä¸€æ ‡è¯†ç¬¦",
                    },
                },
                "required": ["user_id"],
            }
        )

        async def call(
            self, context: ContextWrapper[AstrAgentContext], **kwargs
        ) -> ToolExecResult:
            user_id = kwargs.get("user_id", "")
            if not user_id:
                # ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯ - ä½¿ç”¨æ­£ç¡®çš„æ–¹å¼åˆ›å»ºå®ä¾‹
                return ToolExecResult(content="é”™è¯¯ï¼šç¼ºå°‘ç”¨æˆ·IDå‚æ•°")
            
            # è·å–æ’ä»¶å®ä¾‹ä»¥è®¿é—®é…ç½®çš„å­˜å‚¨è·¯å¾„
            global _plugin_instance
            if _plugin_instance is None:
                return ToolExecResult(content="é”™è¯¯ï¼šæ’ä»¶å®ä¾‹æœªåˆå§‹åŒ–")
            
            # ç¡®ä¿ä½¿ç”¨æœ€æ–°çš„é…ç½®æ•°æ®
            try:
                # ç›´æ¥ä»æ’ä»¶å®ä¾‹è·å–æœ€æ–°é…ç½®
                storage_path = _plugin_instance.storage_path
                debug_mode = _plugin_instance.debug_mode
                if debug_mode:
                    logger.info(f"[FileListTool] ä½¿ç”¨å­˜å‚¨è·¯å¾„: {storage_path}")
            except Exception as e:
                logger.error(f"[FileListTool] è·å–å­˜å‚¨è·¯å¾„æ—¶å‡ºé”™: {e}")
                # ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯
                return ToolExecResult(content=f"è·å–å­˜å‚¨è·¯å¾„æ—¶å‡ºé”™: {str(e)}")
            
            user_storage_path = os.path.join(storage_path, f"user_{user_id}")
            
            if not os.path.exists(user_storage_path):
                return ToolExecResult(content="è¯¥ç”¨æˆ·æš‚æ— æ–‡ä»¶")
            
            record_file = os.path.join(user_storage_path, '.file_records.json')
            if not os.path.exists(record_file):
                return ToolExecResult(content="è¯¥ç”¨æˆ·æš‚æ— æ–‡ä»¶è®°å½•")
            
            try:
                with open(record_file, 'r', encoding='utf-8') as f:
                    records = json.load(f)
                    success_records = [r for r in records if r.get('download_status') == 'success']
                
                if not success_records:
                    return ToolExecResult(content="è¯¥ç”¨æˆ·æš‚æ— æ–‡ä»¶")
                
                # æ ¼å¼åŒ–æ–‡ä»¶ä¿¡æ¯
                file_info_list = []
                for record in success_records:
                    filename = record.get('final_filename', 'unknown')
                    filepath = record.get('file_path', 'unknown')
                    filesize = record.get('file_size', 0)
                    filetype = record.get('file_type', 'unknown')
                    receive_time = record.get('receive_time', 0)
                    
                    # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                    if filesize < 1024:
                        size_str = f"{filesize} B"
                    elif filesize < 1024 * 1024:
                        size_str = f"{filesize / 1024:.1f} KB"
                    elif filesize < 1024 * 1024 * 1024:
                        size_str = f"{filesize / (1024 * 1024):.1f} MB"
                    else:
                        size_str = f"{filesize / (1024 * 1024 * 1024):.1f} GB"
                    
                    # æ ¼å¼åŒ–æ—¶é—´
                    time_str = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(receive_time))
                    
                    file_info_list.append({
                        "filename": filename,
                        "filepath": filepath,
                        "size": size_str,
                        "type": filetype,
                        "receive_time": time_str
                    })
                
                # è¿”å›æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²è€Œä¸æ˜¯JSON
                result_str = "ç”¨æˆ·æ–‡ä»¶åˆ—è¡¨:\n"
                for i, file_info in enumerate(file_info_list, 1):
                    result_str += f"{i}. æ–‡ä»¶å: {file_info['filename']}\n"
                    result_str += f"   è·¯å¾„: {file_info['filepath']}\n"
                    result_str += f"   å¤§å°: {file_info['size']}\n"
                    result_str += f"   ç±»å‹: {file_info['type']}\n"
                    result_str += f"   æ—¶é—´: {file_info['receive_time']}\n\n"
                
                # ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯
                return ToolExecResult(content=result_str.strip())
                
            except Exception as e:
                logger.error(f"[FileListTool] è¯»å–æ–‡ä»¶ä¿¡æ¯æ—¶å‡ºé”™: {e}")
                # ä¿®å¤ToolExecResultè°ƒç”¨é”™è¯¯
                return ToolExecResult(content=f"è¯»å–æ–‡ä»¶ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")

@register("auto_file_handler", "Noctfom", "è‡ªåŠ¨æ–‡ä»¶å¤„ç†å™¨", "1.5.12", "")
class PluginMain(Star):
    def __init__(self, context, config: AstrBotConfig = None):
        super().__init__(context)
        self.context = context
        self.config = config
        
        # å­˜å‚¨æ’ä»¶å®ä¾‹ä¾›LLMå·¥å…·ä½¿ç”¨
        global _plugin_instance
        _plugin_instance = self
        
        # å­˜å‚¨ç­‰å¾…æ¥æ”¶ç¾¤æ–‡ä»¶çš„è¯·æ±‚ {group_id: {user_id: expire_time}}
        self.pending_group_receives = defaultdict(dict)
        
        if config:
            self.storage_path = config.get('storage_path', '/app/storage/auto_file_handler')
            self.auto_cleanup_enabled = config.get('auto_cleanup_enabled', True)
            self.cleanup_days = config.get('cleanup_days', 7)
            self.send_completion_message = config.get('send_completion_message', True)
            self.max_files_per_user = config.get('max_files_per_user', 5)
            self.max_file_size_mb = config.get('max_file_size_mb', 100)
            self.group_whitelist = config.get('group_whitelist', '')
            self.auto_receive_group_files = config.get('auto_receive_group_files', True)
            self.max_files_per_group = config.get('max_files_per_group', 10)
            self.group_file_receive_timeout = config.get('group_file_receive_timeout', 60)
            self.debug_mode = config.get('debug_mode', False)  # æ–°å¢è°ƒè¯•æ¨¡å¼
        else:
            self.storage_path = '/app/storage/auto_file_handler'
            self.auto_cleanup_enabled = True
            self.cleanup_days = 7
            self.send_completion_message = True
            self.max_files_per_user = 5
            self.max_file_size_mb = 100
            self.group_whitelist = ''
            self.auto_receive_group_files = True
            self.max_files_per_group = 10
            self.group_file_receive_timeout = 60
            self.debug_mode = False  # é»˜è®¤å…³é—­è°ƒè¯•æ¨¡å¼
        
        os.makedirs(self.storage_path, exist_ok=True)
        
        if self.auto_cleanup_enabled:
            asyncio.create_task(self._cleanup_task())
        
        # å¯åŠ¨è¶…æ—¶æ£€æŸ¥ä»»åŠ¡
        asyncio.create_task(self._check_pending_timeouts())
        
        # æ³¨å†ŒLLMå·¥å…·
        if LLM_TOOL_SUPPORT:
            try:
                self.context.add_llm_tools(FileListTool())
                if self.debug_mode:
                    logger.info("[FileHandler-1.5.12] LLMå·¥å…·å·²æ³¨å†Œ")
                    logger.info(f"[FileHandler-1.5.12] å½“å‰å­˜å‚¨è·¯å¾„é…ç½®: {self.storage_path}")
            except Exception as e:
                logger.error(f"[FileHandler-1.5.12] æ³¨å†ŒLLMå·¥å…·æ—¶å‡ºé”™: {e}")
        
        logger.info(f"[FileHandler-1.5.12] æ’ä»¶åˆå§‹åŒ–æˆåŠŸ!")
        if self.debug_mode:
            logger.info(f"[FileHandler-1.5.12] å­˜å‚¨è·¯å¾„: {self.storage_path}")
            logger.info(f"[FileHandler-1.5.12] è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if self.debug_mode else 'å…³é—­'}")
    
    async def _check_pending_timeouts(self):
        """å®šæœŸæ£€æŸ¥ç­‰å¾…æ¥æ”¶çš„è¯·æ±‚æ˜¯å¦è¶…æ—¶"""
        while True:
            try:
                current_time = time.time()
                expired_groups = []
                
                for group_id, pending_users in self.pending_group_receives.items():
                    expired_users = []
                    for user_id, expire_time in pending_users.items():
                        if current_time > expire_time:
                            expired_users.append(user_id)
                    
                    # æ¸…ç†è¿‡æœŸç”¨æˆ·å¹¶å‘é€è¶…æ—¶æé†’
                    for user_id in expired_users:
                        del pending_users[user_id]
                        # å‘é€è¶…æ—¶æé†’
                        if self.debug_mode:
                            logger.info(f"[1.5.12] ç¾¤ {group_id} ç”¨æˆ· {user_id} çš„æ–‡ä»¶æ¥æ”¶è¯·æ±‚å·²è¶…æ—¶")
                    
                    # å¦‚æœè¯¥ç¾¤æ²¡æœ‰ç­‰å¾…çš„ç”¨æˆ·äº†ï¼Œæ ‡è®°ä¸ºå¯æ¸…ç†
                    if not pending_users:
                        expired_groups.append(group_id)
                
                # æ¸…ç†ç©ºçš„ç¾¤è®°å½•
                for group_id in expired_groups:
                    del self.pending_group_receives[group_id]
                
                await asyncio.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"[1.5.12] æ£€æŸ¥è¶…æ—¶ä»»åŠ¡å‡ºé”™: {e}")
                await asyncio.sleep(10)
    
    @filter.event_message_type(filter.EventMessageType.ALL)
    async def on_message(self, event: AstrMessageEvent):
        try:
            if not hasattr(event, 'message_obj') or not event.message_obj:
                return
            
            message_obj = event.message_obj
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¾¤èŠæ¶ˆæ¯
            is_group_message = False
            group_id = ""
            if hasattr(message_obj, 'group_id') and message_obj.group_id:
                is_group_message = True
                group_id = str(message_obj.group_id)
            
            # ç¾¤èŠç™½åå•æ£€æŸ¥
            if is_group_message and self.group_whitelist:
                whitelist_groups = [gid.strip() for gid in self.group_whitelist.split(',')]
                if group_id not in whitelist_groups:
                    return  # ä¸åœ¨ç™½åå•ä¸­ï¼Œä¸å¤„ç†
            
            # å¤„ç†æ–‡ä»¶æ¶ˆæ¯
            if hasattr(message_obj, 'message') and message_obj.message:
                for i, component in enumerate(message_obj.message):
                    component_name = component.__class__.__name__ if hasattr(component, '__class__') else 'Unknown'
                    
                    if 'file' in component_name.lower() or component_name in ['File', 'FileComponent']:
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°æ–‡ä»¶ç»„ä»¶ - ç´¢å¼•: {i}, ç±»å‹: {component_name}")
                        
                        # ç¾¤èŠæ–‡ä»¶å¤„ç†
                        if is_group_message:
                            # æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…æ¥æ”¶çš„è¯·æ±‚
                            user_id = self._get_user_id(event)
                            if (group_id in self.pending_group_receives and 
                                user_id in self.pending_group_receives[group_id]):
                                # æœ‰ç­‰å¾…çš„æ¥æ”¶è¯·æ±‚ï¼Œå¤„ç†æ–‡ä»¶
                                del self.pending_group_receives[group_id][user_id]  # æ¸…ç†ç­‰å¾…çŠ¶æ€
                                await self._handle_group_file_v159(event, component, group_id)
                            elif self.auto_receive_group_files:
                                # è‡ªåŠ¨æ¥æ”¶æ¨¡å¼
                                await self._handle_group_file_v159(event, component, group_id)
                            # å¦åˆ™å¿½ç•¥æ–‡ä»¶ï¼ˆæ²¡æœ‰ç­‰å¾…è¯·æ±‚ä¸”æœªå¼€å¯è‡ªåŠ¨æ¥æ”¶ï¼‰
                        else:
                            # ç§èŠæ–‡ä»¶å¤„ç†
                            await self._handle_private_file_v159(event, component)
                        
        except Exception as e:
            logger.error(f"[FileHandler-1.5.12] å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            logger.exception(e)
    
    async def _handle_private_file_v159(self, event: AstrMessageEvent, file_component):
        """å¤„ç†ç§èŠæ–‡ä»¶"""
        try:
            user_id = self._get_user_id(event)
            user_storage_path = os.path.join(self.storage_path, f"user_{user_id}")
            os.makedirs(user_storage_path, exist_ok=True)
            
            if self.debug_mode:
                logger.info(f"[1.5.12] å¤„ç†ç§èŠæ–‡ä»¶ - ç”¨æˆ·: {user_id}, å­˜å‚¨è·¯å¾„: {user_storage_path}")
            
            # æ£€æŸ¥ç”¨æˆ·æ–‡ä»¶æ•°é‡é™åˆ¶å¹¶æé†’åˆ é™¤
            removed_file = None
            if not self._check_user_file_limit(user_id, user_storage_path, self.max_files_per_user):
                record_file = os.path.join(user_storage_path, '.file_records.json')
                if os.path.exists(record_file):
                    with open(record_file, 'r', encoding='utf-8') as f:
                        try:
                            records = json.load(f)
                            if records:
                                removed_file = records[0].get('final_filename', 'æœªçŸ¥æ–‡ä»¶')
                        except:
                            pass
                
                if self.send_completion_message:
                    msg = "âŒ æ–‡ä»¶å­˜å‚¨æ•°é‡å·²è¾¾ä¸Šé™!"
                    if removed_file:
                        msg += f"\nå·²è‡ªåŠ¨åˆ é™¤æœ€æ—§æ–‡ä»¶: {removed_file}"
                    msg += "\nè¯·æ¸…ç†æ—§æ–‡ä»¶åå†è¯•ã€‚"
                    await event.send(event.plain_result(msg))
                return
            
            await self._process_file_download(event, file_component, user_storage_path, "user", user_id)
            
        except Exception as e:
            logger.error(f"[FileHandler-1.5.12] å¤„ç†ç§èŠæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            logger.exception(e)
    
    async def _handle_group_file_v159(self, event: AstrMessageEvent, file_component, group_id):
        """å¤„ç†ç¾¤èŠæ–‡ä»¶"""
        try:
            group_storage_path = os.path.join(self.storage_path, f"group_{group_id}")
            os.makedirs(group_storage_path, exist_ok=True)
            
            if self.debug_mode:
                logger.info(f"[1.5.12] å¤„ç†ç¾¤èŠæ–‡ä»¶ - ç¾¤: {group_id}, å­˜å‚¨è·¯å¾„: {group_storage_path}")
            
            # æ£€æŸ¥ç¾¤æ–‡ä»¶æ•°é‡é™åˆ¶å¹¶æé†’åˆ é™¤
            removed_file = None
            if not self._check_group_file_limit(group_id, group_storage_path, self.max_files_per_group):
                record_file = os.path.join(group_storage_path, '.file_records.json')
                if os.path.exists(record_file):
                    with open(record_file, 'r', encoding='utf-8') as f:
                        try:
                            records = json.load(f)
                            if records:
                                removed_file = records[0].get('final_filename', 'æœªçŸ¥æ–‡ä»¶')
                        except:
                            pass
                
                if self.send_completion_message:
                    msg = "âŒ ç¾¤æ–‡ä»¶å­˜å‚¨æ•°é‡å·²è¾¾ä¸Šé™!"
                    if removed_file:
                        msg += f"\nå·²è‡ªåŠ¨åˆ é™¤æœ€æ—§æ–‡ä»¶: {removed_file}"
                    msg += "\nè¯·æ¸…ç†æ—§æ–‡ä»¶åå†è¯•ã€‚"
                    await event.send(event.plain_result(msg))
                return
            
            await self._process_file_download(event, file_component, group_storage_path, "group", group_id)
            
        except Exception as e:
            logger.error(f"[FileHandler-1.5.12] å¤„ç†ç¾¤èŠæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            logger.exception(e)
    
    async def _process_file_download(self, event: AstrMessageEvent, file_component, storage_path, file_type, identifier):
        """å¤„ç†æ–‡ä»¶ä¸‹è½½çš„é€šç”¨æ–¹æ³•"""
        try:
            file_attrs = self._extract_file_attributes(file_component)
            original_name = self._extract_filename(file_attrs)
            file_url = self._extract_file_url(file_attrs)
            file_id = file_attrs.get('id') or file_attrs.get('file_id')
            file_size = file_attrs.get('size') or file_attrs.get('file_size', 0)
            
            if self.debug_mode:
                logger.info(f"[1.5.12] {file_type}æ–‡ä»¶ä¿¡æ¯ - åç§°: '{original_name}', å¤§å°: {file_size} bytes")
                logger.info(f"[1.5.12] æ–‡ä»¶URL: {file_url}")
                logger.info(f"[1.5.12] æ–‡ä»¶ID: {file_id}")
            
            if self.max_file_size_mb > 0:
                max_size_bytes = self.max_file_size_mb * 1024 * 1024
                if file_size <= 0 and file_url:
                    if 'large' in file_url.lower() or 'video' in file_url.lower():
                        file_size = max_size_bytes + 1
                
                if file_size > max_size_bytes:
                    size_mb = file_size / (1024 * 1024) if file_size > 0 else "æœªçŸ¥"
                    max_mb = self.max_file_size_mb
                    if self.send_completion_message:
                        await event.send(event.plain_result(
                            f"âŒ æ–‡ä»¶è¿‡å¤§æ— æ³•ä¸‹è½½!\n"
                            f"æ–‡ä»¶å¤§å°: {size_mb}MB\n"
                            f"å¤§å°é™åˆ¶: {max_mb}MB"
                        ))
                    return
            
            temp_filename = f"temp_file_{int(time.time())}"
            temp_filepath = os.path.join(storage_path, temp_filename)
            
            if file_url:
                download_success = await self._download_to_temp(file_url, temp_filepath)
                if download_success:
                    detected_type = self._detect_file_type_detailed(temp_filepath)
                    final_filename = self._smart_filename_handling(original_name, detected_type, temp_filepath)
                    final_filepath = os.path.join(storage_path, final_filename)
                    final_filepath = self._ensure_unique_filename(final_filepath)
                    
                    os.rename(temp_filepath, final_filepath)
                    if self.debug_mode:
                        logger.info(f"[1.5.12] æ–‡ä»¶å·²ä¿å­˜: {final_filepath}")
                    
                    record_info = {
                        'identifier': identifier,
                        'type': file_type,
                        'original_name': original_name,
                        'final_filename': final_filename,
                        'file_path': final_filepath,
                        'file_url': file_url,
                        'file_id': file_id,
                        'file_size': os.path.getsize(final_filepath),
                        'file_type': detected_type,
                        'receive_time': time.time(),
                        'sender': event.get_sender_name() if hasattr(event, 'get_sender_name') else 'unknown',
                        'platform': event.get_platform_name() if hasattr(event, 'get_platform_name') else 'unknown',
                        'download_status': 'success'
                    }
                    
                    record_file = os.path.join(storage_path, '.file_records.json')
                    self._save_record(record_file, record_info)
                    
                    if self.send_completion_message:
                        actual_size = os.path.getsize(final_filepath)
                        await self._send_completion_message(event, final_filename, final_filepath, actual_size, detected_type, original_name, file_type)
                        
                else:
                    if os.path.exists(temp_filepath):
                        os.remove(temp_filepath)
                    
                    record_info = {
                        'identifier': identifier,
                        'type': file_type,
                        'original_name': original_name,
                        'file_url': file_url,
                        'file_id': file_id,
                        'file_size': file_size,
                        'receive_time': time.time(),
                        'sender': event.get_sender_name() if hasattr(event, 'get_sender_name') else 'unknown',
                        'platform': event.get_platform_name() if hasattr(event, 'get_platform_name') else 'unknown',
                        'download_status': 'failed'
                    }
                    
                    record_file = os.path.join(storage_path, '.file_records.json')
                    self._save_record(record_file, record_info)
                    
                    if self.send_completion_message:
                        await event.send(event.plain_result(f"âŒ æ–‡ä»¶ {original_name} ä¸‹è½½å¤±è´¥!"))
            else:
                record_info = {
                    'identifier': identifier,
                    'type': file_type,
                    'original_name': original_name,
                    'file_url': file_url,
                    'file_id': file_id,
                    'file_size': file_size,
                    'receive_time': time.time(),
                    'sender': event.get_sender_name() if hasattr(event, 'get_sender_name') else 'unknown',
                    'platform': event.get_platform_name() if hasattr(event, 'get_platform_name') else 'unknown',
                    'download_status': 'no_url'
                }
                
                record_file = os.path.join(storage_path, '.file_records.json')
                self._save_record(record_file, record_info)
            
        except Exception as e:
            logger.error(f"[FileHandler-1.5.12] å¤„ç†æ–‡ä»¶ä¸‹è½½æ—¶å‡ºé”™: {e}")
            logger.exception(e)
    
    # ==================== ç§èŠæŒ‡ä»¤ ====================
    @filter.command("æŸ¥çœ‹æ–‡ä»¶", alias={'/fileinfo'})
    async def view_files(self, event: AstrMessageEvent):
        """æŸ¥çœ‹ç§èŠæ–‡ä»¶"""
        user_id = self._get_user_id(event)
        user_storage_path = os.path.join(self.storage_path, f"user_{user_id}")
        
        record_file = os.path.join(user_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("ğŸ“ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
                success_records = [r for r in records if r.get('download_status') == 'success']
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not success_records:
            await event.send(event.plain_result("ğŸ“ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        success_records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        msg_lines = [f"ğŸ“„ æ‚¨çš„ç§èŠæ–‡ä»¶ (å…±{len(success_records)}ä¸ªæ–‡ä»¶):"]
        msg_lines.append("åºå· | æ–‡ä»¶å | å¤§å° | ç±»å‹ | æ—¶é—´")
        msg_lines.append("-" * 50)
        
        for i, record in enumerate(success_records[:10], 1):
            filename = record.get('final_filename', 'unknown')[:20]
            size = self._format_file_size(record.get('file_size', 0))
            filetype = record.get('file_type', 'unknown')
            time_str = time.strftime('%m-%d %H:%M', time.localtime(record.get('receive_time', 0)))
            
            msg_lines.append(f"{i}. {filename} | {size} | {filetype} | {time_str}")
        
        if len(success_records) > 10:
            msg_lines.append(f"... è¿˜æœ‰{len(success_records) - 10}ä¸ªæ–‡ä»¶")
        
        msg_lines.append("\næŒ‡ä»¤: /å‘é€æ–‡ä»¶ <åºå·/æ–‡ä»¶å>  /åˆ é™¤æ–‡ä»¶ <åºå·/æ–‡ä»¶å>")
        
        await event.send(event.plain_result('\n'.join(msg_lines)))
    
    @filter.command("å‘é€æ–‡ä»¶")
    async def send_file(self, event: AstrMessageEvent, file_identifier: str = ""):
        """å‘é€ç§èŠæ–‡ä»¶"""
        if not file_identifier:
            await event.send(event.plain_result("âŒ è¯·æŒ‡å®šè¦å‘é€çš„æ–‡ä»¶\nç”¨æ³•: /å‘é€æ–‡ä»¶ <åºå·> æˆ– /å‘é€æ–‡ä»¶ <æ–‡ä»¶å>"))
            return
        
        user_id = self._get_user_id(event)
        user_storage_path = os.path.join(self.storage_path, f"user_{user_id}")
        
        record_file = os.path.join(user_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("âŒ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
                success_records = [r for r in records if r.get('download_status') == 'success']
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not success_records:
            await event.send(event.plain_result("âŒ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        success_records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        target_record = None
        
        if file_identifier.isdigit():
            index = int(file_identifier) - 1
            if 0 <= index < len(success_records):
                target_record = success_records[index]
            else:
                await event.send(event.plain_result(f"âŒ åºå·è¶…å‡ºèŒƒå›´ (1-{len(success_records)})"))
                return
        else:
            for record in success_records:
                if file_identifier in record.get('final_filename', ''):
                    target_record = record
                    break
            
            if not target_record:
                for record in success_records:
                    final_name = record.get('final_filename', '').lower()
                    orig_name = record.get('original_name', '').lower()
                    if file_identifier.lower() in final_name or file_identifier.lower() in orig_name:
                        target_record = record
                        break
            
            if not target_record:
                await event.send(event.plain_result(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {file_identifier}"))
                return
        
        file_path = target_record.get('file_path', '')
        if not file_path or not os.path.exists(file_path):
            await event.send(event.plain_result("âŒ æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤"))
            return
        
        filename = target_record.get('final_filename', 'file')
        
        try:
            import astrbot.api.message_components as Comp
            chain = [
                Comp.Plain(f"ğŸ“ æ–‡ä»¶: {filename}\n"),
                Comp.File(file=file_path, name=filename)
            ]
            await event.send(event.chain_result(chain))
            if self.debug_mode:
                logger.info(f"[1.5.12] å·²å‘é€æ–‡ä»¶: {filename}")
            
        except ImportError:
            if hasattr(event, 'file_result'):
                await event.send(event.file_result(file_path, filename))
            else:
                await event.send(event.plain_result(f"ğŸ“ æ–‡ä»¶: {filename}\nè·¯å¾„: {file_path}"))
    
    @filter.command("åˆ é™¤æ–‡ä»¶")
    async def delete_file(self, event: AstrMessageEvent, file_identifier: str = ""):
        """åˆ é™¤ç§èŠæ–‡ä»¶"""
        if not file_identifier:
            await event.send(event.plain_result("âŒ è¯·æŒ‡å®šè¦åˆ é™¤çš„æ–‡ä»¶\nç”¨æ³•: /åˆ é™¤æ–‡ä»¶ <åºå·> æˆ– /åˆ é™¤æ–‡ä»¶ <æ–‡ä»¶å>"))
            return
        
        user_id = self._get_user_id(event)
        user_storage_path = os.path.join(self.storage_path, f"user_{user_id}")
        
        record_file = os.path.join(user_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("âŒ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not records:
            await event.send(event.plain_result("âŒ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        target_record = None
        target_index = -1
        
        if file_identifier.isdigit():
            index = int(file_identifier) - 1
            if 0 <= index < len(records):
                target_record = records[index]
                target_index = index
            else:
                await event.send(event.plain_result(f"âŒ åºå·è¶…å‡ºèŒƒå›´ (1-{len(records)})"))
                return
        else:
            for i, record in enumerate(records):
                if file_identifier in record.get('final_filename', ''):
                    target_record = record
                    target_index = i
                    break
            
            if not target_record:
                for i, record in enumerate(records):
                    final_name = record.get('final_filename', '').lower()
                    orig_name = record.get('original_name', '').lower()
                    if file_identifier.lower() in final_name or file_identifier.lower() in orig_name:
                        target_record = record
                        target_index = i
                        break
            
            if not target_record:
                await event.send(event.plain_result(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {file_identifier}"))
                return
        
        file_path = target_record.get('file_path', '')
        filename = target_record.get('final_filename', 'unknown')
        
        if file_path and os.path.exists(file_path):
            try:
                os.remove(file_path)
                if self.debug_mode:
                    logger.info(f"[1.5.12] å·²åˆ é™¤æ–‡ä»¶: {file_path}")
            except Exception as e:
                logger.error(f"[1.5.12] åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                await event.send(event.plain_result(f"âŒ åˆ é™¤æ–‡ä»¶å¤±è´¥: {filename}"))
                return
        
        records.pop(target_index)
        with open(record_file, 'w', encoding='utf-8') as f:
            json.dump(records, f, ensure_ascii=False, indent=2)
        
        await event.send(event.plain_result(f"âœ… æ–‡ä»¶åˆ é™¤æˆåŠŸ!\næ–‡ä»¶å: {filename}"))
        if self.debug_mode:
            logger.info(f"[1.5.12] å·²åˆ é™¤æ–‡ä»¶è®°å½•: {filename}")
    
    @filter.command("é‡ç½®æ–‡ä»¶")
    async def reset_files(self, event: AstrMessageEvent):
        """é‡ç½®ç§èŠæ–‡ä»¶"""
        user_id = self._get_user_id(event)
        user_storage_path = os.path.join(self.storage_path, f"user_{user_id}")
        
        if not os.path.exists(user_storage_path):
            await event.send(event.plain_result("ğŸ“ æš‚æ— æ–‡ä»¶è®°å½•"))
            return
        
        # åˆ é™¤æ‰€æœ‰æ–‡ä»¶
        deleted_count = 0
        if os.path.exists(user_storage_path):
            for file in os.listdir(user_storage_path):
                file_path = os.path.join(user_storage_path, file)
                if os.path.isfile(file_path) and not file.startswith('.'):
                    try:
                        os.remove(file_path)
                        deleted_count += 1
                        if self.debug_mode:
                            logger.info(f"[1.5.12] å·²åˆ é™¤æ–‡ä»¶: {file_path}")
                    except Exception as e:
                        logger.error(f"[1.5.12] åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        # åˆ é™¤è®°å½•æ–‡ä»¶
        record_file = os.path.join(user_storage_path, '.file_records.json')
        if os.path.exists(record_file):
            try:
                os.remove(record_file)
                if self.debug_mode:
                    logger.info(f"[1.5.12] å·²åˆ é™¤è®°å½•æ–‡ä»¶: {record_file}")
            except Exception as e:
                logger.error(f"[1.5.12] åˆ é™¤è®°å½•æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        await event.send(event.plain_result(f"âœ… ç§èŠæ–‡ä»¶é‡ç½®å®Œæˆ!\nå…±åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶"))
        if self.debug_mode:
            logger.info(f"[1.5.12] ç”¨æˆ· {user_id} çš„ç§èŠæ–‡ä»¶å·²é‡ç½®")
    
    # ==================== ç¾¤èŠæŒ‡ä»¤ ====================
    @filter.command("æŸ¥çœ‹ç¾¤æ–‡ä»¶")
    async def view_group_files(self, event: AstrMessageEvent):
        """æŸ¥çœ‹ç¾¤æ–‡ä»¶ - ä»…ç¾¤èŠå¯ç”¨"""
        if not hasattr(event.message_obj, 'group_id') or not event.message_obj.group_id:
            await event.send(event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨"))
            return
        
        group_id = str(event.message_obj.group_id)
        group_storage_path = os.path.join(self.storage_path, f"group_{group_id}")
        
        record_file = os.path.join(group_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("ğŸ“ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
                success_records = [r for r in records if r.get('download_status') == 'success']
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not success_records:
            await event.send(event.plain_result("ğŸ“ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        success_records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        msg_lines = [f"ğŸ“„ ç¾¤ {group_id} çš„æ–‡ä»¶ (å…±{len(success_records)}ä¸ªæ–‡ä»¶):"]
        msg_lines.append("åºå· | æ–‡ä»¶å | å¤§å° | ç±»å‹ | æ—¶é—´")
        msg_lines.append("-" * 50)
        
        for i, record in enumerate(success_records[:10], 1):
            filename = record.get('final_filename', 'unknown')[:20]
            size = self._format_file_size(record.get('file_size', 0))
            filetype = record.get('file_type', 'unknown')
            time_str = time.strftime('%m-%d %H:%M', time.localtime(record.get('receive_time', 0)))
            
            msg_lines.append(f"{i}. {filename} | {size} | {filetype} | {time_str}")
        
        if len(success_records) > 10:
            msg_lines.append(f"... è¿˜æœ‰{len(success_records) - 10}ä¸ªæ–‡ä»¶")
        
        msg_lines.append("\næŒ‡ä»¤: /å‘é€ç¾¤æ–‡ä»¶ <åºå·/æ–‡ä»¶å>  /åˆ é™¤ç¾¤æ–‡ä»¶ <åºå·/æ–‡ä»¶å>")
        
        await event.send(event.plain_result('\n'.join(msg_lines)))
    
    @filter.command("å‘é€ç¾¤æ–‡ä»¶")
    async def send_group_file(self, event: AstrMessageEvent, file_identifier: str = ""):
        """å‘é€ç¾¤æ–‡ä»¶ - ä»…ç¾¤èŠå¯ç”¨"""
        if not file_identifier:
            await event.send(event.plain_result("âŒ è¯·æŒ‡å®šè¦å‘é€çš„æ–‡ä»¶\nç”¨æ³•: /å‘é€ç¾¤æ–‡ä»¶ <åºå·> æˆ– /å‘é€ç¾¤æ–‡ä»¶ <æ–‡ä»¶å>"))
            return
        
        if not hasattr(event.message_obj, 'group_id') or not event.message_obj.group_id:
            await event.send(event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨"))
            return
        
        group_id = str(event.message_obj.group_id)
        group_storage_path = os.path.join(self.storage_path, f"group_{group_id}")
        
        record_file = os.path.join(group_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("âŒ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
                success_records = [r for r in records if r.get('download_status') == 'success']
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not success_records:
            await event.send(event.plain_result("âŒ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        success_records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        target_record = None
        
        if file_identifier.isdigit():
            index = int(file_identifier) - 1
            if 0 <= index < len(success_records):
                target_record = success_records[index]
            else:
                await event.send(event.plain_result(f"âŒ åºå·è¶…å‡ºèŒƒå›´ (1-{len(success_records)})"))
                return
        else:
            for record in success_records:
                if file_identifier in record.get('final_filename', ''):
                    target_record = record
                    break
            
            if not target_record:
                for record in success_records:
                    final_name = record.get('final_filename', '').lower()
                    orig_name = record.get('original_name', '').lower()
                    if file_identifier.lower() in final_name or file_identifier.lower() in orig_name:
                        target_record = record
                        break
            
            if not target_record:
                await event.send(event.plain_result(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {file_identifier}"))
                return
        
        file_path = target_record.get('file_path', '')
        if not file_path or not os.path.exists(file_path):
            await event.send(event.plain_result("âŒ æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤"))
            return
        
        filename = target_record.get('final_filename', 'file')
        
        try:
            import astrbot.api.message_components as Comp
            chain = [
                Comp.Plain(f"ğŸ“ æ–‡ä»¶: {filename}\n"),
                Comp.File(file=file_path, name=filename)
            ]
            await event.send(event.chain_result(chain))
            if self.debug_mode:
                logger.info(f"[1.5.12] å·²å‘é€ç¾¤æ–‡ä»¶: {filename}")
            
        except ImportError:
            if hasattr(event, 'file_result'):
                await event.send(event.file_result(file_path, filename))
            else:
                await event.send(event.plain_result(f"ğŸ“ æ–‡ä»¶: {filename}\nè·¯å¾„: {file_path}"))
    
    @filter.command("åˆ é™¤ç¾¤æ–‡ä»¶")
    async def delete_group_file(self, event: AstrMessageEvent, file_identifier: str = ""):
        """åˆ é™¤ç¾¤æ–‡ä»¶ - ä»…ç¾¤èŠå¯ç”¨"""
        if not file_identifier:
            await event.send(event.plain_result("âŒ è¯·æŒ‡å®šè¦åˆ é™¤çš„æ–‡ä»¶\nç”¨æ³•: /åˆ é™¤ç¾¤æ–‡ä»¶ <åºå·> æˆ– /åˆ é™¤ç¾¤æ–‡ä»¶ <æ–‡ä»¶å>"))
            return
        
        if not hasattr(event.message_obj, 'group_id') or not event.message_obj.group_id:
            await event.send(event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨"))
            return
        
        group_id = str(event.message_obj.group_id)
        group_storage_path = os.path.join(self.storage_path, f"group_{group_id}")
        
        record_file = os.path.join(group_storage_path, '.file_records.json')
        if not os.path.exists(record_file):
            await event.send(event.plain_result("âŒ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
        except:
            await event.send(event.plain_result("âŒ è¯»å–è®°å½•æ–‡ä»¶å‡ºé”™"))
            return
        
        if not records:
            await event.send(event.plain_result("âŒ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        records.sort(key=lambda x: x.get('receive_time', 0), reverse=True)
        
        target_record = None
        target_index = -1
        
        if file_identifier.isdigit():
            index = int(file_identifier) - 1
            if 0 <= index < len(records):
                target_record = records[index]
                target_index = index
            else:
                await event.send(event.plain_result(f"âŒ åºå·è¶…å‡ºèŒƒå›´ (1-{len(records)})"))
                return
        else:
            for i, record in enumerate(records):
                if file_identifier in record.get('final_filename', ''):
                    target_record = record
                    target_index = i
                    break
            
            if not target_record:
                for i, record in enumerate(records):
                    final_name = record.get('final_filename', '').lower()
                    orig_name = record.get('original_name', '').lower()
                    if file_identifier.lower() in final_name or file_identifier.lower() in orig_name:
                        target_record = record
                        target_index = i
                        break
            
            if not target_record:
                await event.send(event.plain_result(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {file_identifier}"))
                return
        
        file_path = target_record.get('file_path', '')
        filename = target_record.get('final_filename', 'unknown')
        
        if file_path and os.path.exists(file_path):
            try:
                os.remove(file_path)
                if self.debug_mode:
                    logger.info(f"[1.5.12] å·²åˆ é™¤ç¾¤æ–‡ä»¶: {file_path}")
            except Exception as e:
                logger.error(f"[1.5.12] åˆ é™¤ç¾¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                await event.send(event.plain_result(f"âŒ åˆ é™¤ç¾¤æ–‡ä»¶å¤±è´¥: {filename}"))
                return
        
        records.pop(target_index)
        with open(record_file, 'w', encoding='utf-8') as f:
            json.dump(records, f, ensure_ascii=False, indent=2)
        
        await event.send(event.plain_result(f"âœ… ç¾¤æ–‡ä»¶åˆ é™¤æˆåŠŸ!\næ–‡ä»¶å: {filename}"))
        if self.debug_mode:
            logger.info(f"[1.5.12] å·²åˆ é™¤ç¾¤æ–‡ä»¶è®°å½•: {filename}")
    
    @filter.command("é‡ç½®ç¾¤æ–‡ä»¶")
    async def reset_group_files(self, event: AstrMessageEvent):
        """é‡ç½®ç¾¤æ–‡ä»¶ - ä»…ç¾¤èŠå¯ç”¨"""
        if not hasattr(event.message_obj, 'group_id') or not event.message_obj.group_id:
            await event.send(event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨"))
            return
        
        group_id = str(event.message_obj.group_id)
        group_storage_path = os.path.join(self.storage_path, f"group_{group_id}")
        
        if not os.path.exists(group_storage_path):
            await event.send(event.plain_result("ğŸ“ æš‚æ— ç¾¤æ–‡ä»¶è®°å½•"))
            return
        
        # åˆ é™¤æ‰€æœ‰æ–‡ä»¶
        deleted_count = 0
        if os.path.exists(group_storage_path):
            for file in os.listdir(group_storage_path):
                file_path = os.path.join(group_storage_path, file)
                if os.path.isfile(file_path) and not file.startswith('.'):
                    try:
                        os.remove(file_path)
                        deleted_count += 1
                        if self.debug_mode:
                            logger.info(f"[1.5.12] å·²åˆ é™¤ç¾¤æ–‡ä»¶: {file_path}")
                    except Exception as e:
                        logger.error(f"[1.5.12] åˆ é™¤ç¾¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        # åˆ é™¤è®°å½•æ–‡ä»¶
        record_file = os.path.join(group_storage_path, '.file_records.json')
        if os.path.exists(record_file):
            try:
                os.remove(record_file)
                if self.debug_mode:
                    logger.info(f"[1.5.12] å·²åˆ é™¤ç¾¤è®°å½•æ–‡ä»¶: {record_file}")
            except Exception as e:
                logger.error(f"[1.5.12] åˆ é™¤ç¾¤è®°å½•æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        await event.send(event.plain_result(f"âœ… ç¾¤ {group_id} æ–‡ä»¶é‡ç½®å®Œæˆ!\nå…±åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶"))
        if self.debug_mode:
            logger.info(f"[1.5.12] ç¾¤ {group_id} çš„æ–‡ä»¶å·²é‡ç½®")
    
    @filter.command("æ¥æ”¶ç¾¤æ–‡ä»¶")
    async def receive_group_file(self, event: AstrMessageEvent):
        """æ¥æ”¶ç¾¤æ–‡ä»¶ - æ”¹è¿›ç‰ˆé€»è¾‘"""
        if not hasattr(event.message_obj, 'group_id') or not event.message_obj.group_id:
            await event.send(event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨"))
            return
        
        if self.auto_receive_group_files:
            await event.send(event.plain_result("âœ… è‡ªåŠ¨æ¥æ”¶ç¾¤æ–‡ä»¶å·²å¼€å¯ï¼Œæ— éœ€æ‰‹åŠ¨æ¥æ”¶"))
            return
        
        group_id = str(event.message_obj.group_id)
        user_id = self._get_user_id(event)
        
        # è®¾ç½®ç­‰å¾…æ¥æ”¶çŠ¶æ€
        expire_time = time.time() + self.group_file_receive_timeout
        self.pending_group_receives[group_id][user_id] = expire_time
        
        timeout_msg = f"{self.group_file_receive_timeout}"
        await event.send(event.plain_result(
            f"ğŸ’¡ è¯·åœ¨ {timeout_msg} ç§’å†…å‘é€è¦æ¥æ”¶çš„æ–‡ä»¶\n"
            f"æ”¯æŒç›´æ¥å‘é€æˆ–å¼•ç”¨æ–‡ä»¶æ¶ˆæ¯\n"
            f"è¶…æ—¶å°†è‡ªåŠ¨å–æ¶ˆæ¥æ”¶"
        ))
        
        if self.debug_mode:
            logger.info(f"[1.5.12] ç¾¤ {group_id} ç”¨æˆ· {user_id} å¼€å§‹ç­‰å¾…æ–‡ä»¶æ¥æ”¶ï¼Œè¶…æ—¶æ—¶é—´: {timeout_msg}ç§’")
    
    def _get_user_id(self, event: AstrMessageEvent):
        """è·å–ç”¨æˆ·ID"""
        try:
            if hasattr(event, 'message_obj') and event.message_obj:
                message_obj = event.message_obj
                if hasattr(message_obj, 'sender') and message_obj.sender:
                    user_id = getattr(message_obj.sender, 'user_id', None)
                    if user_id:
                        return str(user_id)
            
            sender_name = event.get_sender_name() if hasattr(event, 'get_sender_name') else 'unknown'
            platform = event.get_platform_name() if hasattr(event, 'get_platform_name') else 'unknown'
            return f"{sender_name}_{platform}"
            
        except Exception as e:
            logger.error(f"[1.5.12] è·å–ç”¨æˆ·IDæ—¶å‡ºé”™: {e}")
            return "unknown_user"
    
    def _check_user_file_limit(self, user_id, user_storage_path, max_files):
        """æ£€æŸ¥ç”¨æˆ·æ–‡ä»¶æ•°é‡é™åˆ¶"""
        try:
            record_file = os.path.join(user_storage_path, '.file_records.json')
            if not os.path.exists(record_file):
                return True
            
            with open(record_file, 'r', encoding='utf-8') as f:
                try:
                    records = json.load(f)
                    success_records = [r for r in records if r.get('download_status') == 'success']
                    
                    if len(success_records) >= max_files:
                        self._remove_oldest_file(success_records, user_storage_path, record_file)
                        return False
                    else:
                        return True
                        
                except:
                    return True
                    
        except Exception as e:
            logger.error(f"[1.5.12] æ£€æŸ¥ç”¨æˆ·æ–‡ä»¶é™åˆ¶æ—¶å‡ºé”™: {e}")
            return True
    
    def _check_group_file_limit(self, group_id, group_storage_path, max_files):
        """æ£€æŸ¥ç¾¤æ–‡ä»¶æ•°é‡é™åˆ¶"""
        try:
            record_file = os.path.join(group_storage_path, '.file_records.json')
            if not os.path.exists(record_file):
                return True
            
            with open(record_file, 'r', encoding='utf-8') as f:
                try:
                    records = json.load(f)
                    success_records = [r for r in records if r.get('download_status') == 'success']
                    
                    if len(success_records) >= max_files:
                        self._remove_oldest_file(success_records, group_storage_path, record_file)
                        return False
                    else:
                        return True
                        
                except:
                    return True
                    
        except Exception as e:
            logger.error(f"[1.5.12] æ£€æŸ¥ç¾¤æ–‡ä»¶é™åˆ¶æ—¶å‡ºé”™: {e}")
            return True
    
    def _remove_oldest_file(self, records, storage_path, record_file):
        """åˆ é™¤æœ€æ—§çš„æ–‡ä»¶"""
        try:
            records.sort(key=lambda x: x.get('receive_time', 0))
            oldest_record = records[0]
            
            file_path = oldest_record.get('file_path', '')
            if file_path and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    if self.debug_mode:
                        logger.info(f"[1.5.12] å·²åˆ é™¤æœ€æ—§æ–‡ä»¶: {file_path}")
                except Exception as e:
                    logger.error(f"[1.5.12] åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            
            remaining_records = records[1:]
            with open(record_file, 'w', encoding='utf-8') as f:
                json.dump(remaining_records, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"[1.5.12] åˆ é™¤æœ€æ—§æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def _smart_filename_handling(self, original_name, detected_type, file_path):
        """æ™ºèƒ½æ–‡ä»¶åå¤„ç†"""
        try:
            if (original_name and 
                original_name not in ['unknown_file', 'qqdownloadftnv5'] and
                len(original_name) > 5 and
                '.' in original_name):
                
                original_ext = os.path.splitext(original_name)[1].lower()
                detected_ext = detected_type.lower()
                
                if (original_ext == detected_ext or 
                    (original_ext in ['.docx', '.doc'] and detected_ext in ['.docx', '.doc']) or
                    (original_ext in ['.xlsx', '.xls'] and detected_ext in ['.xlsx', '.xls']) or
                    (original_ext in ['.pptx', '.ppt'] and detected_ext in ['.pptx', '.ppt'])):
                    
                    if self.debug_mode:
                        logger.info(f"[1.5.12] ä½¿ç”¨æœ‰æ•ˆçš„åŸå§‹æ–‡ä»¶å: {original_name}")
                    return self._sanitize_filename(original_name)
            
            name_without_ext = os.path.splitext(original_name)[0]
            if name_without_ext and name_without_ext not in ['unknown_file', 'qqdownloadftnv5']:
                final_name = f"{name_without_ext}{detected_type}"
            else:
                timestamp = int(time.time())
                final_name = f"file_{timestamp}{detected_type}"
            
            return self._sanitize_filename(final_name)
            
        except Exception as e:
            logger.error(f"[1.5.12] æ™ºèƒ½æ–‡ä»¶åå¤„ç†å‡ºé”™: {e}")
            timestamp = int(time.time())
            return f"file_{timestamp}{detected_type}"
    
    async def _send_completion_message(self, event: AstrMessageEvent, filename, filepath, filesize, filetype, original_name, file_type):
        """å‘é€å®Œæˆæ¶ˆæ¯"""
        try:
            size_str = self._format_file_size(filesize)
            
            if original_name in ['unknown_file', 'qqdownloadftnv5'] or not original_name:
                completion_msg = f"""âœ… {'ç¾¤' if file_type == 'group' else 'ç§èŠ'}æ–‡ä»¶æ¥æ”¶æˆåŠŸ!
æ–‡ä»¶å: {filename}
å¤§å°: {size_str}
ç±»å‹: {filetype}
è·¯å¾„: {filepath}

ğŸ’¡ æç¤º: ç”±äºç¯å¢ƒé™åˆ¶ï¼ŒåŸå§‹æ–‡ä»¶åæ— æ³•è·å–
ç³»ç»Ÿå·²ä¸ºæ‚¨ç”Ÿæˆæ–°çš„æ–‡ä»¶å: {filename}"""
            else:
                completion_msg = f"""âœ… {'ç¾¤' if file_type == 'group' else 'ç§èŠ'}æ–‡ä»¶æ¥æ”¶æˆåŠŸ!
åŸå§‹å: {original_name}
ä¿å­˜ä¸º: {filename}
å¤§å°: {size_str}
ç±»å‹: {filetype}
è·¯å¾„: {filepath}"""
            
            await event.send(event.plain_result(completion_msg))
            if self.debug_mode:
                logger.info(f"[1.5.12] å·²å‘é€å®Œæˆæ¶ˆæ¯: {filename}")
            
        except Exception as e:
            logger.error(f"[1.5.12] å‘é€å®Œæˆæ¶ˆæ¯å‡ºé”™: {e}")
    
    def _format_file_size(self, size_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
        else:
            return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"
    
    def _detect_file_type_detailed(self, filepath):
        """å¢å¼ºçš„æ–‡ä»¶ç±»å‹æ£€æµ‹ - ä¿®å¤PPTXè¯†åˆ«é—®é¢˜"""
        try:
            with open(filepath, 'rb') as f:
                header = f.read(1024)
            
            if self.debug_mode:
                logger.info(f"[1.5.12] æ–‡ä»¶å¤´æ£€æµ‹å¼€å§‹ - æ–‡ä»¶: {filepath}")
            
            # EXEæ–‡ä»¶
            if header.startswith(b'MZ'):
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹åˆ°EXEæ–‡ä»¶")
                return '.exe'
            
            # ZIPç³»åˆ—
            if header.startswith(b'PK'):
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹åˆ°ZIPç³»åˆ—æ–‡ä»¶")
                with zipfile.ZipFile(filepath, 'r') as zip_ref:
                    namelist = zip_ref.namelist()
                    if self.debug_mode:
                        logger.info(f"[1.5.12] ZIPæ–‡ä»¶å†…å®¹: {namelist[:10]}")  # åªæ˜¾ç¤ºå‰10ä¸ª
                    
                    # PPTXæ–‡ä»¶æ£€æµ‹
                    if any(name.startswith('ppt/') for name in namelist):
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°PPTXæ–‡ä»¶")
                        return '.pptx'
                    
                    # DOCXæ–‡ä»¶æ£€æµ‹
                    if '[Content_Types].xml' in namelist:
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°DOCXæ–‡ä»¶")
                        return '.docx'
                    
                    # XLSXæ–‡ä»¶æ£€æµ‹
                    if 'xl/' in str(namelist):
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°XLSXæ–‡ä»¶")
                        return '.xlsx'
                    
                    # PPTæ–‡ä»¶æ£€æµ‹
                    if any(name.startswith('PowerPoint Document') for name in namelist):
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°PPTæ–‡ä»¶")
                        return '.ppt'
                
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹ä¸ºæ™®é€šZIPæ–‡ä»¶")
                return '.zip'
            
            # TARæ–‡ä»¶
            if header.startswith(b'ustar\x00') or header.startswith(b'ustar\x20'):
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹åˆ°TARæ–‡ä»¶")
                return '.tar'
            
            # GZæ–‡ä»¶
            if header.startswith(b'\x1f\x8b'):
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹åˆ°GZæ–‡ä»¶")
                return '.gz'
            
            # 7Z
            elif header.startswith(b'7z\xbc\xaf\x27\x1c'):
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹åˆ°7Zæ–‡ä»¶")
                return '.7z'
            
            # RAR
            elif header.startswith(b'Rar!\x1a\x07\x00') or header.startswith(b'Rar!\x1a\x07\x01\x00'):
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹åˆ°RARæ–‡ä»¶")
                return '.rar'
            
            # Officeæ–‡æ¡£
            elif header.startswith(b'\xd0\xcf\x11\xe0\xa1\xb1\x1a\xe1'):
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹åˆ°Officeæ–‡æ¡£")
                return '.doc'
            
            # PDF
            elif header.startswith(b'%PDF'):
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹åˆ°PDFæ–‡ä»¶")
                return '.pdf'
            
            # å›¾ç‰‡æ ¼å¼
            elif header.startswith(b'\xff\xd8\xff'):
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹åˆ°JPGæ–‡ä»¶")
                return '.jpg'
            elif header.startswith(b'\x89PNG\r\n\x1a\n'):
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹åˆ°PNGæ–‡ä»¶")
                return '.png'
            elif header.startswith(b'GIF87a') or header.startswith(b'GIF89a'):
                if self.debug_mode:
                    logger.info(f"[1.5.12] æ£€æµ‹åˆ°GIFæ–‡ä»¶")
                return '.gif'
            
            # æ–‡æœ¬æ–‡ä»¶æ£€æµ‹
            try:
                with open(filepath, 'rb') as f:
                    sample = f.read(512)
                
                if all(c < 128 for c in sample[:100]) and b'\x00' not in sample[:100]:
                    sample_str = sample.decode('utf-8', errors='ignore')
                    if self.debug_mode:
                        logger.info(f"[1.5.12] æ£€æµ‹åˆ°æ–‡æœ¬æ–‡ä»¶ï¼Œå†…å®¹é¢„è§ˆ: {sample_str[:100]}")
                    
                    if '<?xml' in sample_str[:100]:
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°XMLæ–‡ä»¶")
                        return '.xml'
                    elif '<?php' in sample_str[:100]:
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°PHPæ–‡ä»¶")
                        return '.php'
                    elif '<html' in sample_str.lower()[:100]:
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°HTMLæ–‡ä»¶")
                        return '.html'
                    elif 'def ' in sample_str[:200] and ':' in sample_str[:200]:
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°Pythonæ–‡ä»¶")
                        return '.py'
                    elif '#include' in sample_str[:200]:
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°C/C++æ–‡ä»¶")
                        return '.cpp'
                    elif 'public class' in sample_str[:200] or 'public static' in sample_str[:200]:
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°Javaæ–‡ä»¶")
                        return '.java'
                    elif 'function' in sample_str[:200] or 'var ' in sample_str[:200]:
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°JavaScriptæ–‡ä»¶")
                        return '.js'
                    elif '@charset' in sample_str[:100] or 'background:' in sample_str[:200]:
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°CSSæ–‡ä»¶")
                        return '.css'
                    else:
                        if self.debug_mode:
                            logger.info(f"[1.5.12] æ£€æµ‹åˆ°æ™®é€šæ–‡æœ¬æ–‡ä»¶")
                        return '.txt'
                else:
                    if self.debug_mode:
                        logger.info(f"[1.5.12] æ£€æµ‹åˆ°äºŒè¿›åˆ¶æ–‡ä»¶")
                    return '.bin'
                    
            except Exception as e:
                if self.debug_mode:
                    logger.error(f"[1.5.12] æ–‡æœ¬æ–‡ä»¶æ£€æµ‹å‡ºé”™: {e}")
                return '.bin'
                
        except Exception as e:
            logger.error(f"[1.5.12] æ–‡ä»¶ç±»å‹æ£€æµ‹å‡ºé”™: {e}")
            if self.debug_mode:
                logger.exception(e)
            return '.bin'
    
    def _extract_file_attributes(self, file_component):
        """æå–æ–‡ä»¶å±æ€§"""
        attrs = {}
        try:
            attr_names = [attr for attr in dir(file_component) if not attr.startswith('_')]
            for attr in attr_names:
                try:
                    value = getattr(file_component, attr)
                    if isinstance(value, (str, int, float, bool, type(None))):
                        attrs[attr] = value
                except:
                    pass
        except Exception as e:
            logger.error(f"[1.5.12] æå–å±æ€§æ—¶å‡ºé”™: {e}")
        return attrs
    
    def _extract_filename(self, file_attrs):
        """æå–æ–‡ä»¶å"""
        filename = (file_attrs.get('name') or 
                   file_attrs.get('filename') or 
                   file_attrs.get('file_name') or 
                   'unknown_file')
        result = self._sanitize_filename(filename) if filename else 'unknown_file'
        if self.debug_mode:
            logger.info(f"[1.5.12] æå–æ–‡ä»¶å: '{filename}' -> '{result}'")
        return result
    
    def _extract_file_url(self, file_attrs):
        """æå–æ–‡ä»¶URL"""
        url = (file_attrs.get('url') or 
               file_attrs.get('file_url') or 
               file_attrs.get('path') or 
               file_attrs.get('file_path'))
        if self.debug_mode and url:
            logger.info(f"[1.5.12] æå–æ–‡ä»¶URL: {url[:100]}...")  # åªæ˜¾ç¤ºå‰100å­—ç¬¦
        return url
    
    async def _download_to_temp(self, url, temp_path):
        """ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶"""
        try:
            if self.debug_mode:
                logger.info(f"[1.5.12] å¼€å§‹ä¸‹è½½: {url[:100]}...")  # åªæ˜¾ç¤ºå‰100å­—ç¬¦
            
            timeout = aiohttp.ClientTimeout(total=120)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        with open(temp_path, 'wb') as f:
                            async for chunk in response.content.iter_chunked(8192):
                                f.write(chunk)
                        if self.debug_mode:
                            logger.info(f"[1.5.12] ä¸‹è½½æˆåŠŸ: {temp_path}")
                        return True
                    else:
                        if self.debug_mode:
                            logger.error(f"[1.5.12] ä¸‹è½½å¤±è´¥ HTTP {response.status}")
                        return False
                        
        except Exception as e:
            if self.debug_mode:
                logger.error(f"[1.5.12] ä¸‹è½½å‡ºé”™: {e}")
            return False
    
    async def _cleanup_task(self):
        """è‡ªåŠ¨æ¸…ç†ä»»åŠ¡"""
        while True:
            try:
                if self.auto_cleanup_enabled:
                    await asyncio.sleep(3600)
                    self._cleanup_expired_files()
            except Exception as e:
                logger.error(f"[1.5.12] æ¸…ç†ä»»åŠ¡å‡ºé”™: {e}")
                await asyncio.sleep(60)
    
    def _cleanup_expired_files(self):
        """æ¸…ç†è¿‡æœŸæ–‡ä»¶"""
        try:
            if not os.path.exists(self.storage_path):
                return
                
            for item in os.listdir(self.storage_path):
                item_path = os.path.join(self.storage_path, item)
                if os.path.isdir(item_path):
                    record_file = os.path.join(item_path, '.file_records.json')
                    if not os.path.exists(record_file):
                        continue
                    
                    with open(record_file, 'r', encoding='utf-8') as f:
                        try:
                            records = json.load(f)
                        except:
                            records = []
                    
                    current_time = time.time()
                    expired_records = []
                    valid_records = []
                    
                    for record in records:
                        receive_time = record.get('receive_time', 0)
                        file_path = record.get('file_path', '')
                        
                        if current_time - receive_time > self.cleanup_days * 24 * 3600:
                            expired_records.append(record)
                            if file_path and os.path.exists(file_path):
                                try:
                                    os.remove(file_path)
                                    if self.debug_mode:
                                        logger.info(f"[1.5.12] å·²åˆ é™¤è¿‡æœŸæ–‡ä»¶: {file_path}")
                                except Exception as e:
                                    logger.error(f"[1.5.12] åˆ é™¤æ–‡ä»¶å‡ºé”™: {e}")
                        else:
                            valid_records.append(record)
                    
                    with open(record_file, 'w', encoding='utf-8') as f:
                        json.dump(valid_records, f, ensure_ascii=False, indent=2)
                    
                    if expired_records and self.debug_mode:
                        logger.info(f"[1.5.12] ç›®å½• {item} æ¸…ç†äº† {len(expired_records)} ä¸ªè¿‡æœŸæ–‡ä»¶")
                        
        except Exception as e:
            logger.error(f"[1.5.12] æ¸…ç†è¿‡æœŸæ–‡ä»¶å‡ºé”™: {e}")
    
    def _ensure_unique_filename(self, filepath):
        """ç¡®ä¿æ–‡ä»¶åå”¯ä¸€"""
        counter = 1
        name, ext = os.path.splitext(filepath)
        
        while os.path.exists(filepath):
            filepath = f"{name}_{counter}{ext}"
            counter += 1
            if counter > 1000:
                filepath = f"{name}_{int(time.time())}_{counter}{ext}"
                break
        
        if self.debug_mode and counter > 1:
            logger.info(f"[1.5.12] æ–‡ä»¶åå†²çªï¼Œç”Ÿæˆå”¯ä¸€æ–‡ä»¶å: {filepath}")
        
        return filepath
    
    def _sanitize_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶å"""
        if not filename:
            return 'unnamed_file.bin'
        
        illegal_chars = '<>:"/\\|?*'
        for char in illegal_chars:
            filename = filename.replace(char, '_')
        
        filename = ''.join(char for char in filename if ord(char) >= 32)
        filename = re.sub(r'_+', '_', filename)
        filename = filename.strip('_. ')
        
        return filename if filename else 'unnamed_file.bin'
    
    def _save_record(self, record_file, record_info):
        """ä¿å­˜è®°å½•"""
        try:
            records = []
            if os.path.exists(record_file):
                with open(record_file, 'r', encoding='utf-8') as f:
                    try:
                        records = json.load(f)
                    except:
                        records = []
            
            records.append(record_info)
            
            with open(record_file, 'w', encoding='utf-8') as f:
                json.dump(records, f, ensure_ascii=False, indent=2)
                
            if self.debug_mode:
                logger.info(f"[1.5.12] è®°å½•å·²ä¿å­˜")
                
        except Exception as e:
            logger.error(f"[1.5.12] ä¿å­˜è®°å½•å‡ºé”™: {e}")
    
    @filter.command("filestatus")
    async def file_status(self, event: AstrMessageEvent):
        """æŸ¥çœ‹æ’ä»¶çŠ¶æ€"""
        status_msg = f"""ğŸ“ æ–‡ä»¶å¤„ç†å™¨çŠ¶æ€ (v1.5.12):
å­˜å‚¨è·¯å¾„: {self.storage_path}
è‡ªåŠ¨æ¸…ç†: {'âœ… å¯ç”¨' if self.auto_cleanup_enabled else 'âŒ ç¦ç”¨'}
æ¸…ç†å¤©æ•°: {self.cleanup_days}å¤©
å®Œæˆæ¶ˆæ¯: {'âœ… å¯ç”¨' if self.send_completion_message else 'âŒ ç¦ç”¨'}
ç§èŠæ–‡ä»¶é™åˆ¶: {self.max_files_per_user}ä¸ª/ç”¨æˆ·
ç¾¤èŠæ–‡ä»¶é™åˆ¶: {self.max_files_per_group}ä¸ª/ç¾¤
æ–‡ä»¶å¤§å°é™åˆ¶: {self.max_file_size_mb}MB
ç¾¤èŠç™½åå•: {'å…¨éƒ¨ç¾¤' if not self.group_whitelist else self.group_whitelist}
è‡ªåŠ¨æ¥æ”¶ç¾¤æ–‡ä»¶: {'âœ… å¯ç”¨' if self.auto_receive_group_files else 'âŒ ç¦ç”¨'}
æ¥æ”¶è¶…æ—¶æ—¶é—´: {self.group_file_receive_timeout}ç§’
LLMå·¥å…·æ”¯æŒ: {'âœ… å¯ç”¨' if LLM_TOOL_SUPPORT else 'âŒ ç¦ç”¨'}
è°ƒè¯•æ¨¡å¼: {'âœ… å¼€å¯' if self.debug_mode else 'âŒ å…³é—­'}"""
        
        await event.send(event.plain_result(status_msg))

AutoFileHandlerPlugin = PluginMain
